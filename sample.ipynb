{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132102,"status":"ok","timestamp":1712475897440,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"4oc1v2eS6E5O","outputId":"4e23b4d3-2b9a-4741-df65-9b7f9fb7359a"},"outputs":[],"source":["# prompt: 在.ipynb中安装依赖。pip install torch numpy transformers datasets tiktoken wandb tqdm\n","\n","!pip install torch numpy transformers datasets tiktoken wandb tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0M81Ci3l7Enl"},"outputs":[],"source":["!pip install easyquotation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7116,"status":"ok","timestamp":1712460456806,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"RpBPjTQ55l_S","outputId":"c17fad10-7eb0-400c-ed6e-62fbe4eb2ee1"},"outputs":[],"source":["\"\"\"\n","Sample from a trained model\n","\"\"\"\n","import os\n","import pickle\n","from contextlib import nullcontext\n","import torch\n","import tiktoken\n","from model import GPTConfig, GPT\n","import json\n","from operator import itemgetter\n","import numpy as np\n","from collections import Counter\n","\n","\n","# -----------------------------------------------------------------------------\n","init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n","out_dir = 'out-stock' # ignored if init_from is not 'resume'\n","start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n","num_samples = 10 # number of samples to draw\n","max_new_tokens = 500 # number of tokens generated in each sample\n","temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n","top_k = 10 # retain only the top_k most likely tokens, clamp others to have 0 probability\n","seed = 1337\n","device = 'cuda' if torch.cuda.is_available() else 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n","dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n","compile = False # use PyTorch 2.0 to compile the model to be faster\n","\n","device\n","# -----------------------------------------------------------------------------\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"executionInfo":{"elapsed":1717,"status":"ok","timestamp":1712471803241,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"LNq6Ki5G5l_U","outputId":"e4fff213-df4f-4b76-ba78-2f65d972ff25"},"outputs":[],"source":["import pandas as pd\n","\n","# torch.manual_seed(seed)\n","# torch.cuda.manual_seed(seed)\n","torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n","torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n","device_type = 'cpu' # for later use in torch.autocast\n","ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n","ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n","\n","# model\n","if init_from == 'resume':\n","    # init from a model saved in a specific directory\n","    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n","    checkpoint = torch.load(ckpt_path, map_location=device)\n","    gptconf = GPTConfig(**checkpoint['model_args'])\n","    model = GPT(gptconf)\n","    state_dict = checkpoint['model']\n","    unwanted_prefix = '_orig_mod.'\n","    for k,v in list(state_dict.items()):\n","        if k.startswith(unwanted_prefix):\n","            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n","    model.load_state_dict(state_dict)\n","\n","\n","model.eval()\n","model.to(device)\n","\n","\n","datadir = os.path.join('data', 'stock')\n","\n","# meta数据\n","meta = {}\n","with open(os.path.join(datadir, 'meta.pkl'), 'r') as f:\n","    meta = json.load(f)\n","    meta_vocab_size = meta['vocab_size']\n","    meta_vocab_size = 31\n","def decode(id):\n","    return meta['itos'][str(id)]\n","def decode_arr(ids):\n","    return [decode(id) for id in ids]\n","def encode(s):\n","    return [meta['stoi'][c] for c in s]\n","\n","\n","pd_train_data = pd.read_csv(os.path.join(datadir, 'train.csv'))\n","for append_name in sorted([name for name in os.listdir(datadir) if name.startswith('real_time_')]):\n","    data_append = pd.read_csv(os.path.join(datadir, append_name))\n","    pd_train_data = pd.concat([pd_train_data, data_append], ignore_index=True)\n","\n","pd_train_data = pd_train_data.iloc[1:,:2049]\n","pd_train_data.reset_index(drop=True, inplace=True)\n","pd_train_data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1712460624153,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"CmgwnzzU5l_V","outputId":"5ef4f9b1-d978-4b6b-aad4-fe30a573d3a0"},"outputs":[],"source":["def transform_dataframe_id(df):\n","  \"\"\"\n","  Transforms values in a dataframe according to the specified rules.\n","\n","  Args:\n","      df: The pandas dataframe to transform.\n","\n","  Returns:\n","      A new pandas dataframe with transformed values.\n","  \"\"\"\n","\n","  def transform_pri_chg_id(value):\n","    if value == -100:\n","      return 10\n","    else:\n","      new_value = int((value - 0.9) * 100)\n","      if new_value < 0:\n","        return 0\n","      elif new_value > 30:\n","        return 30\n","      else:\n","        return new_value\n","\n","  # Apply the transformation function to each column in the dataframe\n","  transformed_df = df.applymap(transform_pri_chg_id)\n","\n","  return transformed_df\n","\n","train_data = transform_dataframe_id(pd_train_data.iloc[:, 1:])\n","train_data = torch.from_numpy(train_data.to_numpy().astype(np.int64))\n","print(train_data.shape)\n","train_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1712466548940,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"0rLu1REI5l_V","outputId":"0f687866-fbed-4920-b0e7-1b13edafcce3"},"outputs":[],"source":["# torch.manual_seed(333)\n","\n","import random\n","\n","block_size = 32\n","\n","def get_batch(split, i, index=None):\n","    data = train_data\n","    pd_data = pd_train_data\n","\n","    if index is None:\n","        dates, codes = data.shape\n","        index_code = torch.tensor([code for code in range(codes) ])\n","        index_date = torch.tensor([i])\n","\n","        # (batch, block)\n","        x = torch.stack([data[index_date:index_date+block_size, i].squeeze() for i in index_code])\n","        # (batch, block)\n","        y = torch.stack([data[index_date+1:index_date+1+block_size, i].squeeze() for i in index_code])\n","\n","    # index_first = index\n","    # if index is None:\n","    #     index_first = index_date[0].item()\n","    #     index_code = index_code[0].item()\n","    # for i in range(block_size):\n","    #     print(f'x is date={pd_data.iloc[index_first+i, 0]}, chg={pd_data.iloc[index_first+i, index_code+1]:<6}, code={pd_data.columns[index_code+1]}, code_id={index_code+1}')\n","    # print('----')\n","    # for i in range(block_size):\n","    #      print(f'y is date={pd_data.iloc[index_first+i+1, 0]}, chg={pd_data.iloc[index_first+i+1, index_code+1]:<6}, code={pd_data.columns[index_code+1]}, code_id={index_code+1}')\n","\n","    return x, y\n","\n","print(train_data.shape)\n","x, y = get_batch('train', 100)\n","\n","print(f'x.shape is {x.shape}, y.shape is {y.shape}')\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1708,"status":"ok","timestamp":1712471630277,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"l-lDm1Ks5l_V","outputId":"6bde9ba7-4bf5-4aed-c2f0-17f657da7c63"},"outputs":[],"source":["from operator import itemgetter\n","import numpy as np\n","from collections import Counter\n","\n","size_data = len(pd_train_data)\n","index = size_data - block_size - 48\n","len_dates, len_codes = train_data.shape\n","\n","\n","pd_data = pd_train_data\n","x, y = get_batch('train', index)\n","\n","idx = model.generate(x, 1)\n","\n","print(idx.shape)\n","print(idx)\n","\n","last_dim = idx.shape[-1] - 1\n","sorted_tensor, indices = torch.sort(idx[:, last_dim], descending=True)\n","print(sorted_tensor)\n","print(indices)\n","\n","result = torch.stack((indices, sorted_tensor), dim=1)\n","\n","# 输出前5个最大值及其键\n","print(\"---前5个最小的值及其键：\")\n","for i_code, predict in result[-5:]:\n","  i_code = i_code.item()\n","  print(f'-----id={i_code}, code={pd_train_data.iloc[0, i_code+1]}, predict={predict}')\n","  for i in range(block_size-2, block_size):\n","      print(f'date={pd_data.iloc[index+i, 0]}, chg={pd_data.iloc[index+i, i_code+1]:<6}, code={pd_data.columns[i_code+1]}, code_id={i_code}')\n","  if index + block_size < len(pd_train_data):\n","      print(f'date={pd_train_data.iloc[index+block_size, 0]}, code={pd_data.columns[i_code+1]}, idx={idx[i_code][-1]}, predict={((0.9+float(idx[i_code][-1].item())/100 -1)*100):.2f}%, chg={((pd_train_data.iloc[index+block_size, i_code+1])-1)*100:.2f}%')\n","\n","print('-------------------')\n","print('-------------------')\n","print('-------------------')\n","print('---最大的')\n","for i_code, predict in result[0:5]:\n","  i_code = i_code.item()\n","  print(f'-----id={i_code}, code={pd_train_data.iloc[0, i_code+1]}, predict={predict}')\n","  print(f'idx is {idx[i_code]}')\n","  for i in range(block_size-2, block_size):\n","      print(f'date={pd_data.iloc[index+i, 0]}, chg={pd_data.iloc[index+i, i_code+1]:<6}, code={pd_data.columns[i_code+1]}, code_id={i_code}')\n","  if index + block_size < len(pd_train_data):\n","      print(f'date={pd_train_data.iloc[index+block_size, 0]}, code={pd_data.columns[i_code+1]}, idx={idx[i_code][-1]}, predict={((0.9+float(idx[i_code][-1].item())/100 -1)*100):.2f}%, chg={((pd_train_data.iloc[index+block_size, i_code+1])-1)*100:.2f}%')\n","\n","\n","import easyquotation\n","quotation = easyquotation.use('tencent') # 新浪 ['sina'] 腾讯 ['tencent', 'qq']\n","\n","def real_time(codes):\n","    all = quotation.stocks(codes)\n","    for code, info in all.items():\n","        print(f\"code is {info['code']}, name is {info['name']}, price is {info['now']}, chg is {info['涨跌(%)']}\")\n","\n","print('---最大的实时数据')\n","codes = []\n","for key, value in result[:5]:\n","    code = pd_train_data.columns[key.item()+1][:-3]\n","    codes.append(code)\n","real_time(codes)\n","\n","print('---最小的实时数据')\n","codes = []\n","for key, value in result[-5:]:\n","    code = pd_train_data.columns[key.item()+1][:-3]\n","    codes.append(code)\n","codes.append('002565')\n","real_time(codes)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ren545457803/nanoGPT/blob/stock/sample.ipynb","timestamp":1712280988833}]},"kernelspec":{"display_name":"nanogpt","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
