{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample from a trained model\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out-stock' # ignored if init_from is not 'resume'\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 10 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config is GPTConfig(block_size=5, vocab_size=4096, n_layer=8, n_head=8, n_embd=512, dropout=0, bias=False)\n",
      "number of parameters: 27.27M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_date</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <th>000002.SZ</th>\n",
       "      <th>000004.SZ</th>\n",
       "      <th>000005.SZ</th>\n",
       "      <th>000006.SZ</th>\n",
       "      <th>000007.SZ</th>\n",
       "      <th>000008.SZ</th>\n",
       "      <th>000009.SZ</th>\n",
       "      <th>000010.SZ</th>\n",
       "      <th>...</th>\n",
       "      <th>603320.SH</th>\n",
       "      <th>603321.SH</th>\n",
       "      <th>603322.SH</th>\n",
       "      <th>603323.SH</th>\n",
       "      <th>603324.SH</th>\n",
       "      <th>603325.SH</th>\n",
       "      <th>603326.SH</th>\n",
       "      <th>603327.SH</th>\n",
       "      <th>603328.SH</th>\n",
       "      <th>603329.SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230104</td>\n",
       "      <td>1.0399</td>\n",
       "      <td>1.0461</td>\n",
       "      <td>1.0020</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>1.0339</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>1.0027</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0483</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>1.0156</td>\n",
       "      <td>1.0235</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>1.0524</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>1.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230105</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>1.0214</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>1.0091</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>1.0167</td>\n",
       "      <td>1.0188</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>1.0061</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>1.0149</td>\n",
       "      <td>0.9851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230106</td>\n",
       "      <td>1.0097</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>1.0016</td>\n",
       "      <td>1.0601</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>1.0036</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230109</td>\n",
       "      <td>1.0123</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>1.0083</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>1.0179</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0211</td>\n",
       "      <td>1.0221</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>1.0085</td>\n",
       "      <td>1.0104</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>1.0050</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>1.0061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230110</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>1.0011</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>1.0013</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0031</td>\n",
       "      <td>1.0148</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>20240328</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>1.0033</td>\n",
       "      <td>1.0532</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>1.0104</td>\n",
       "      <td>1.0274</td>\n",
       "      <td>1.0212</td>\n",
       "      <td>1.0106</td>\n",
       "      <td>1.0314</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>1.0165</td>\n",
       "      <td>1.0102</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>1.0197</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>1.0810</td>\n",
       "      <td>1.0534</td>\n",
       "      <td>1.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>20240329</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>1.0290</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>1.0261</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0285</td>\n",
       "      <td>1.0236</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>1.0089</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>1.0323</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>1.0558</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>1.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>20240401</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>-100.0000</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0226</td>\n",
       "      <td>1.0127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0245</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>1.0144</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.0173</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>1.0228</td>\n",
       "      <td>1.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>20240402</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>1.0037</td>\n",
       "      <td>1.0126</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0193</td>\n",
       "      <td>1.0084</td>\n",
       "      <td>1.0039</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>1.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>20240403</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>1.0251</td>\n",
       "      <td>0.9918</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>1.0223</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>1.0191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows × 4097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trade_date  000001.SZ  000002.SZ  000004.SZ  000005.SZ  000006.SZ  \\\n",
       "0      20230104     1.0399     1.0461     1.0020     1.0000     1.0065   \n",
       "1      20230105     1.0112     1.0136     0.9890     1.0214     0.9610   \n",
       "2      20230106     1.0097     0.9943     0.9756     0.9895     0.9696   \n",
       "3      20230109     1.0123     0.9771     1.0083     0.9947     0.9930   \n",
       "4      20230110     0.9757     1.0011     0.9907     0.9894     0.9860   \n",
       "..          ...        ...        ...        ...        ...        ...   \n",
       "297    20240328     0.9962     1.0033     1.0532  -100.0000     1.0104   \n",
       "298    20240329     1.0029     0.9740     0.9741  -100.0000     1.0180   \n",
       "299    20240401     1.0114     0.9978     0.9953  -100.0000     1.0051   \n",
       "300    20240402     0.9915     0.9465     0.9733     1.0000     0.9899   \n",
       "301    20240403     0.9905     0.9706     0.9575     1.0000     0.9924   \n",
       "\n",
       "     000007.SZ  000008.SZ  000009.SZ  000010.SZ  ...  603320.SH  603321.SH  \\\n",
       "0       0.9740     1.0339     0.9943     1.0027  ...     1.0483     1.0070   \n",
       "1       0.9987     0.9959     1.0091     0.9786  ...     1.0079     1.0167   \n",
       "2       0.9949     0.9918     1.0016     1.0601  ...     1.0079     0.9945   \n",
       "3       1.0179     0.9959     0.9927     0.9588  ...     1.0211     1.0221   \n",
       "4       1.0013     0.9917     0.9951     0.9677  ...     1.0031     1.0148   \n",
       "..         ...        ...        ...        ...  ...        ...        ...   \n",
       "297     1.0274     1.0212     1.0106     1.0314  ...     1.0242     1.0165   \n",
       "298     0.9933     1.0290     1.0086     1.0261  ...     1.0285     1.0236   \n",
       "299     1.0000     1.0000     1.0226     1.0127  ...     1.0245     1.0259   \n",
       "300     0.9821     0.9798     1.0037     1.0126  ...     1.0193     1.0084   \n",
       "301     1.0251     0.9918     0.9982     0.9793  ...     0.9879     0.9972   \n",
       "\n",
       "     603322.SH  603323.SH  603324.SH  603325.SH  603326.SH  603327.SH  \\\n",
       "0       1.0156     1.0235     0.9767  -100.0000     1.0524     0.9876   \n",
       "1       1.0188     0.9958     1.0061  -100.0000     0.9858     1.0094   \n",
       "2       1.0000     0.9916     1.0052  -100.0000     1.0036     0.9926   \n",
       "3       0.9933     1.0085     1.0104  -100.0000     0.9688     1.0050   \n",
       "4       0.9921     0.9853     1.0054  -100.0000     0.9901     0.9900   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "297     1.0102     0.9824     1.0197     1.0007     1.0095     1.0810   \n",
       "298     0.9732     1.0089     0.9934     1.0323     0.9009     1.0558   \n",
       "299     1.0144     1.0177     1.0173     1.0056     1.0288     0.9876   \n",
       "300     1.0039     1.0022     1.0349     0.9962     0.9720     0.9600   \n",
       "301     0.9760     0.9957     0.9843     0.9735     1.0223     0.9784   \n",
       "\n",
       "     603328.SH  603329.SH  \n",
       "0       0.9941     1.0006  \n",
       "1       1.0149     0.9851  \n",
       "2       0.9985     0.9928  \n",
       "3       1.0029     1.0061  \n",
       "4       1.0000     0.9813  \n",
       "..         ...        ...  \n",
       "297     1.0534     1.0301  \n",
       "298     0.9873     1.0068  \n",
       "299     1.0228     1.0067  \n",
       "300     0.9874     1.0081  \n",
       "301     0.9915     1.0191  \n",
       "\n",
       "[302 rows x 4097 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "datadir = os.path.join('data', 'stock')\n",
    "\n",
    "# meta数据\n",
    "meta = {}\n",
    "with open(os.path.join(datadir, 'meta.pkl'), 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    meta_vocab_size = meta['vocab_size']\n",
    "    meta_vocab_size = 4096\n",
    "def decode(id):\n",
    "    return meta['itos'][str(id)]\n",
    "def decode_arr(ids):\n",
    "    return [decode(id) for id in ids]\n",
    "def encode(s):\n",
    "    return [meta['stoi'][c] for c in s]\n",
    "\n",
    "pd_train_data = pd.read_csv(os.path.join(datadir, 'train.csv'))\n",
    "for append_name in sorted([name for name in os.listdir(datadir) if name.startswith('real_time_')]):\n",
    "    data_append = pd.read_csv(os.path.join(datadir, append_name))\n",
    "    pd_train_data = pd.concat([pd_train_data, data_append], ignore_index=True)\n",
    "\n",
    "pd_train_data = pd_train_data.iloc[1:,:meta_vocab_size+1]\n",
    "pd_train_data.reset_index(drop=True, inplace=True)\n",
    "pd_train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2573, 2089, 2356,  ..., 2372, 4023,  333],\n",
       "        [2438, 2499, 2393,  ..., 1245, 1382, 4003],\n",
       "        [2682, 1868, 1614,  ..., 1339, 1498, 3414],\n",
       "        ...,\n",
       "        [2451, 2477, 1745,  ..., 1573, 1896, 2386],\n",
       "        [2482, 2477, 1954,  ...,  181, 3060, 3192],\n",
       "        [1635, 2810, 2666,  ..., 3024, 3060,  297]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trans_frame_to_id(dataframe):\n",
    "    train_data = dataframe.iloc[:, 1:]\n",
    "    # 对所有行，都取前10个最大的\n",
    "    def top_n(row, n):\n",
    "        # return row.nlargest(n).values\n",
    "        return row.nlargest(n).index.tolist()\n",
    "\n",
    "    n = 20\n",
    "    data_top_10 = train_data.apply(top_n, axis=1, n=n)\n",
    "\n",
    "    # 将结果转换为 [266, 10] 的形状\n",
    "    data_transformed = pd.DataFrame(data_top_10.tolist(), index=train_data.index)\n",
    "\n",
    "    def to_id(row):\n",
    "        return encode(row)\n",
    "    \n",
    "    data_transformed = data_transformed.apply(to_id, axis=1)\n",
    "    data_transformed = torch.stack([torch.tensor(row) for row in data_transformed])\n",
    "    return data_transformed\n",
    "\n",
    "train_data = trans_frame_to_id(pd_train_data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(333)\n",
    "\n",
    "block_size = 5\n",
    "\n",
    "def get_batch(split, i, batch=1):\n",
    "    data = train_data\n",
    "\n",
    "    indices = torch.randint(len(data)-1-block_size, (1, ))\n",
    "    indices = torch.tensor([i] * batch)\n",
    "\n",
    "    # (batch, block)\n",
    "    x = torch.stack([data[i:i+block_size] for i in indices])\n",
    "    x = x.gather(2, torch.randint(x.shape[2], (x.shape[0], x.shape[1], 1))).squeeze(-1)\n",
    "\n",
    "    # (batch, block)\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in indices])\n",
    "    y = y.gather(2, torch.randint(y.shape[2], (y.shape[0], y.shape[1], 1))).squeeze(-1)\n",
    "\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('val', 295, 1000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date=20240328, chg=1.1426, code=300887.SZ, code_id=2349\n",
      "date=20240329, chg=1.1209, code=300430.SZ, code_id=1908\n",
      "date=20240401, chg=1.2   , code=300618.SZ, code_id=2091\n",
      "date=20240402, chg=1.1701, code=300890.SZ, code_id=2352\n",
      "date=20240403, chg=1.1003, code=000701.SZ, code_id=229\n",
      "[(2366, 58), (2028, 55), (1062, 38), (1702, 38), (1800, 37), (1889, 36), (1780, 31), (1908, 31), (1915, 31), (163, 31), (2029, 31), (1952, 30), (2566, 30), (2643, 29), (2299, 28), (1701, 28), (1943, 26), (38, 26), (2071, 26), (2180, 25), (816, 24), (2337, 24), (2142, 22), (2803, 21), (1771, 21), (2273, 20), (2169, 20), (2478, 19), (1955, 18), (2352, 18), (690, 18), (2023, 17), (1946, 17), (1518, 17), (2223, 16), (2807, 16), (3398, 16), (2573, 16), (2764, 15), (2591, 15), (2417, 14), (1700, 13), (2495, 13), (1953, 12), (2077, 12), (1808, 11), (2217, 11), (782, 11), (2394, 11), (1791, 11), (2471, 11), (1477, 11), (2523, 10), (2804, 10), (2833, 10), (2344, 10), (3060, 10), (2750, 10), (2519, 9), (2300, 9), (2005, 9), (2664, 9), (1625, 8), (2830, 8), (2735, 8), (1566, 8), (2384, 8), (349, 8), (2357, 8), (2704, 8), (730, 8), (2024, 8), (2661, 8), (2797, 8), (2423, 8), (1528, 8), (2765, 7), (1804, 7), (2067, 7), (1678, 7), (1870, 7), (2246, 7), (1126, 7), (3509, 7), (2844, 7), (2046, 7), (1811, 7), (2262, 7), (362, 6), (1827, 6), (2633, 6), (2411, 6), (1728, 6), (2772, 6), (2333, 6), (2271, 6), (2431, 6), (2197, 6), (1605, 6), (1802, 6), (2635, 6), (1783, 6), (1335, 5), (1643, 5), (2837, 5), (2723, 5), (1603, 5), (2681, 5), (2782, 5), (1829, 5), (2234, 5), (1588, 5), (2407, 5), (789, 5), (2716, 5), (2200, 5), (2365, 5), (1517, 5), (1582, 5), (2245, 5), (1598, 4), (2000, 4), (2276, 4), (1660, 4), (2728, 4), (2598, 4), (2693, 4), (2616, 4), (1632, 4), (2587, 4), (1733, 4), (1321, 4), (2047, 4), (55, 4), (1637, 4), (2050, 4), (2789, 4), (2570, 4), (1746, 3), (2027, 3), (2309, 3), (2362, 3), (505, 3), (1691, 3), (724, 3), (3850, 3), (1205, 3), (1601, 3), (2134, 3), (1170, 3), (2654, 3), (3705, 3), (1931, 3), (2051, 3), (1534, 3), (2809, 3), (2786, 3), (818, 3), (3510, 3), (2582, 3), (2343, 3), (2413, 3), (2249, 3), (1120, 3), (3600, 3), (2621, 3), (2484, 3), (932, 3), (2822, 3), (1963, 3), (2158, 3), (2599, 3), (2741, 3), (2630, 3), (2110, 3), (2554, 2), (1652, 2), (2199, 2), (2156, 2), (2419, 2), (1883, 2), (2540, 2), (1740, 2), (2671, 2), (2502, 2), (1675, 2), (2085, 2), (2421, 2), (3525, 2), (2475, 2), (2658, 2), (2819, 2), (2375, 2), (2181, 2), (3723, 2), (2320, 2), (2183, 2), (2632, 2), (681, 2), (2496, 2), (1253, 2), (2656, 2), (1667, 2), (1902, 2), (2182, 2), (1831, 2), (2697, 2), (2559, 2), (1322, 2), (1577, 2), (153, 2), (1838, 2), (1273, 2), (1923, 2), (1590, 2), (2444, 2), (2938, 2), (2270, 2), (1972, 2), (1772, 2), (1201, 1), (192, 1), (1822, 1), (1782, 1), (2184, 1), (826, 1), (1645, 1), (2162, 1), (983, 1), (1997, 1), (2738, 1), (1681, 1), (1713, 1), (2203, 1), (2577, 1), (3846, 1), (723, 1), (1901, 1), (1745, 1), (2034, 1), (2049, 1), (2638, 1), (3367, 1), (2694, 1), (2779, 1), (369, 1), (1613, 1), (2418, 1), (2451, 1), (577, 1), (321, 1), (1139, 1), (1781, 1), (2285, 1), (1976, 1), (2119, 1), (1752, 1), (1805, 1), (1961, 1), (4040, 1), (2404, 1), (1927, 1), (2026, 1), (927, 1), (768, 1), (2597, 1), (1527, 1), (2788, 1), (2579, 1), (1204, 1), (2518, 1), (2011, 1), (3034, 1), (2469, 1), (866, 1), (341, 1), (2567, 1), (2717, 1), (1379, 1), (3026, 1), (2349, 1), (2745, 1), (2583, 1), (1882, 1), (2236, 1), (507, 1), (2553, 1), (2713, 1), (1774, 1), (2481, 1), (2306, 1), (1951, 1), (2817, 1), (1656, 1), (593, 1), (1591, 1), (2354, 1), (2558, 1), (2250, 1), (2454, 1), (720, 1), (3912, 1), (2186, 1), (2742, 1), (3282, 1)]\n",
      "305\n",
      "---前5个最小的值及其键：\n",
      "code=002207.SZ, Key: 720, Value: 1\n",
      "code=603079.SH, Key: 3912, Value: 1\n",
      "code=300716.SZ, Key: 2186, Value: 1\n",
      "code=301333.SZ, Key: 2742, Value: 1\n",
      "code=600577.SH, Key: 3282, Value: 1\n",
      "---最大的\n",
      "code=300904.SZ, Key: 2366, Value: 58\n",
      "code=300554.SZ, Key: 2028, Value: 55\n",
      "code=002565.SZ, Key: 1062, Value: 38\n",
      "code=300210.SZ, Key: 1702, Value: 38\n",
      "code=300313.SZ, Key: 1800, Value: 37\n",
      "---最大的实时数据\n",
      "code is 300904, name is 威力传动, price is 52.48, chg is -6.54\n",
      "code is 300554, name is 三超新材, price is 23.4, chg is -3.11\n",
      "code is 002565, name is 顺灏股份, price is 3.32, chg is 4.08\n",
      "code is 300210, name is 森远股份, price is 11.15, chg is -2.02\n",
      "code is 300313, name is *ST天山, price is 7.92, chg is -1.61\n",
      "---最小的实时数据\n",
      "code is 002207, name is 准油股份, price is 6.7, chg is 10.02\n",
      "code is 603079, name is 圣达生物, price is 11.29, chg is -4.32\n",
      "code is 300716, name is 泉为科技, price is 9.77, chg is -6.95\n",
      "code is 301333, name is 诺思格, price is 54.56, chg is 2.65\n",
      "code is 600577, name is 精达股份, price is 4.74, chg is -3.46\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "size_data = len(pd_train_data)\n",
    "index = size_data - block_size - 0\n",
    "\n",
    "\n",
    "haha = []\n",
    "\n",
    "def predect():\n",
    "    pd_data = pd_train_data \n",
    "    x, y = get_batch('val', index, 2000)\n",
    "\n",
    "    idx = model.generate(x, 1)\n",
    "\n",
    "    # 统计频次\n",
    "    counter = Counter(idx[:, -1].tolist())\n",
    "    # 获取出现频次最多的值\\\n",
    "    global haha\n",
    "    haha = counter.most_common()\n",
    "\n",
    "    for i in range(block_size):\n",
    "        print(f'date={pd_data.iloc[index+i, 0]}, chg={pd_data.loc[index+i, decode(idx[0][i].item())]:<6}, code={decode(idx[0][i].item())}, code_id={idx[0][i].item()}')\n",
    "\n",
    "predect()\n",
    "\n",
    "print(haha)\n",
    "print(len(haha))\n",
    "\n",
    "\n",
    "# 输出前5个最大值及其键\n",
    "print(\"---前5个最小的值及其键：\")\n",
    "for key, value in haha[-5:]:\n",
    "    print(f\"code={decode(key)}, Key: {key}, Value: {value}\")\n",
    "    if index + block_size < len(pd_train_data):\n",
    "        if index + block_size < len(pd_train_data):\n",
    "            print(f'date={pd_train_data.iloc[index+block_size, 0]}, code={decode(key)}, code_id={key}, chg={((pd_train_data.loc[index+block_size, decode(key)])-1)*100:.2f}%')\n",
    "print('---最大的')\n",
    "for key, value in haha[:5]:\n",
    "    print(f\"code={decode(key)}, Key: {key}, Value: {value}\")\n",
    "    if index + block_size < len(pd_train_data):\n",
    "        if index + block_size < len(pd_train_data):\n",
    "            print(f'date={pd_train_data.iloc[index+block_size, 0]}, code={decode(key)}, code_id={key}, chg={((pd_train_data.loc[index+block_size, decode(key)])-1)*100:.2f}%')\n",
    "\n",
    "\n",
    "import easyquotation\n",
    "quotation = easyquotation.use('tencent') # 新浪 ['sina'] 腾讯 ['tencent', 'qq'] \n",
    "\n",
    "def real_time(codes):\n",
    "    all = quotation.stocks(codes) \n",
    "    for code, info in all.items():\n",
    "        print(f\"code is {info['code']}, name is {info['name']}, price is {info['now']}, chg is {info['涨跌(%)']}\")\n",
    "\n",
    "print('---最大的实时数据')\n",
    "codes = []\n",
    "for key, value in haha[:5]:\n",
    "    code = decode(key)[:-3]\n",
    "    codes.append(code)\n",
    "real_time(codes)\n",
    "\n",
    "print('---最小的实时数据')\n",
    "codes = []\n",
    "for key, value in haha[-5:]:\n",
    "    code = decode(key)[:-3]\n",
    "    codes.append(code)\n",
    "codes.append('002565')\n",
    "real_time(codes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
