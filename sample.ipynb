{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample from a trained model\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out-stock' # ignored if init_from is not 'resume'\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 10 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "datadir = os.path.join('data', 'stock')\n",
    "\n",
    "# meta数据\n",
    "meta = {}\n",
    "with open(os.path.join(datadir, 'meta.pkl'), 'r') as f:\n",
    "    meta = json.load(f)\n",
    "    meta_vocab_size = meta['vocab_size']\n",
    "    meta_vocab_size = 4096\n",
    "def decode(id):\n",
    "    return meta['itos'][str(id)]\n",
    "def decode_arr(ids):\n",
    "    return [decode(id) for id in ids]\n",
    "def encode(s):\n",
    "    return [meta['stoi'][c] for c in s]\n",
    "\n",
    "pd_train_data = pd.read_csv(os.path.join(datadir, 'train.csv'))\n",
    "for append_name in sorted([name for name in os.listdir(datadir) if name.startswith('real_time_')]):\n",
    "    data_append = pd.read_csv(os.path.join(datadir, append_name))\n",
    "    pd_train_data = pd.concat([pd_train_data, data_append], ignore_index=True)\n",
    "\n",
    "pd_train_data = pd_train_data.iloc[1:,:meta_vocab_size+1]\n",
    "pd_train_data.reset_index(drop=True, inplace=True)\n",
    "pd_train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_frame_to_id(dataframe):\n",
    "    train_data = dataframe.iloc[:, 1:]\n",
    "    # 对所有行，都取前10个最大的\n",
    "    def top_n(row, n):\n",
    "        # return row.nlargest(n).values\n",
    "        return row.nlargest(n).index.tolist()\n",
    "\n",
    "    n = 20\n",
    "    data_top_10 = train_data.apply(top_n, axis=1, n=n)\n",
    "\n",
    "    # 将结果转换为 [266, 10] 的形状\n",
    "    data_transformed = pd.DataFrame(data_top_10.tolist(), index=train_data.index)\n",
    "\n",
    "    def to_id(row):\n",
    "        return encode(row)\n",
    "    \n",
    "    data_transformed = data_transformed.apply(to_id, axis=1)\n",
    "    data_transformed = torch.stack([torch.tensor(row) for row in data_transformed])\n",
    "    return data_transformed\n",
    "\n",
    "train_data = trans_frame_to_id(pd_train_data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(333)\n",
    "\n",
    "block_size = 5\n",
    "\n",
    "def get_batch(split, i, batch=1):\n",
    "    data = train_data\n",
    "\n",
    "    indices = torch.randint(len(data)-1-block_size, (1, ))\n",
    "    indices = torch.tensor([i] * batch)\n",
    "\n",
    "    # (batch, block)\n",
    "    x = torch.stack([data[i:i+block_size] for i in indices])\n",
    "    x = x.gather(2, torch.randint(x.shape[2], (x.shape[0], x.shape[1], 1))).squeeze(-1)\n",
    "\n",
    "    # (batch, block)\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in indices])\n",
    "    y = y.gather(2, torch.randint(y.shape[2], (y.shape[0], y.shape[1], 1))).squeeze(-1)\n",
    "\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('val', 295, 1000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "size_data = len(pd_train_data)\n",
    "index = size_data - block_size - 2\n",
    "print(index)\n",
    "\n",
    "\n",
    "haha = []\n",
    "\n",
    "def predect():\n",
    "    pd_data = pd_train_data \n",
    "    x, y = get_batch('val', index, 2000)\n",
    "\n",
    "    idx = model.generate(x, 1)\n",
    "\n",
    "    # 统计频次\n",
    "    counter = Counter(idx[:, -1].tolist())\n",
    "    # 获取出现频次最多的值\\\n",
    "    global haha\n",
    "    haha = counter.most_common()\n",
    "\n",
    "    for i in range(block_size):\n",
    "        print(f'date={pd_data.iloc[index+i, 0]}, chg={pd_data.loc[index+i, decode(idx[0][i].item())]:<6}, code={decode(idx[0][i].item())}, code_id={idx[0][i].item()}')\n",
    "\n",
    "predect()\n",
    "\n",
    "print(haha)\n",
    "print(len(haha))\n",
    "\n",
    "# 输出前5个最大值及其键\n",
    "print(\"前5个最大的值及其键：\")\n",
    "for key, value in haha[:5]:\n",
    "    print(f\"code={decode(key)}, Key: {key}, Value: {value}\")\n",
    "    if index + block_size < len(pd_train_data):\n",
    "        print(f'date={pd_train_data.iloc[index+block_size, 0]}, chg={pd_train_data.loc[index+block_size, decode(key)]:<6}, code={decode(key)}, code_id={key}')\n",
    "\n",
    "import easyquotation\n",
    "quotation = easyquotation.use('tencent') # 新浪 ['sina'] 腾讯 ['tencent', 'qq'] \n",
    "\n",
    "codes = []\n",
    "for key, value in haha[:5]:\n",
    "    code = decode(key)[:-3]\n",
    "    codes.append(code)\n",
    "\n",
    "codes.append('002407')\n",
    "all = quotation.stocks(codes) \n",
    "for code, info in all.items():\n",
    "    print(f\"code is {info['code']}, name is {info['name']}, price is {info['now']}, chg is {info['涨跌(%)']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
