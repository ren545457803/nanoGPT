{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample from a trained model\n",
    "\"\"\"\n",
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import GPTConfig, GPT\n",
    "import json\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out-stock' # ignored if init_from is not 'resume'\n",
    "start = \"\\n\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 500 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 10 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = False # use PyTorch 2.0 to compile the model to be faster\n",
    "# -----------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.61M\n",
      "Loading meta from data/stock/meta.pkl...\n",
      "name is transformer.wpe.weight, params is Parameter containing:\n",
      "tensor([[-0.0295, -0.0224,  0.0681,  ...,  0.0531,  0.0359,  0.0362],\n",
      "        [-0.0003,  0.0019,  0.0434,  ..., -0.0273, -0.0077,  0.0400],\n",
      "        [ 0.0228, -0.0376,  0.0236,  ...,  0.0058,  0.0123,  0.0410],\n",
      "        ...,\n",
      "        [ 0.0242, -0.0071,  0.0525,  ...,  0.0158, -0.0151,  0.0173],\n",
      "        [ 0.0165, -0.0487,  0.0080,  ..., -0.0029, -0.0228,  0.0300],\n",
      "        [ 0.0057, -0.0481,  0.0328,  ..., -0.0303,  0.0222,  0.0212]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.0.ln_1.weight, params is Parameter containing:\n",
      "tensor([0.8220, 0.7370, 0.8032, 0.6294, 0.8202, 0.6684, 0.8476, 0.6883, 0.8903,\n",
      "        0.6361, 0.8297, 0.8298, 0.8982, 0.7807, 0.8863, 0.6275, 0.8073, 0.7070,\n",
      "        0.8641, 0.7677, 0.8325, 0.6485, 0.8234, 0.6023, 0.7877, 0.6848, 0.8401,\n",
      "        0.5607, 0.8445, 0.7290, 0.8139, 0.6776, 0.8685, 0.6314, 0.8475, 0.7155,\n",
      "        0.8767, 0.7475, 0.8254, 0.6641, 0.8174, 0.6340, 0.8756, 0.6669, 0.9626,\n",
      "        0.7507, 0.8086, 0.7686, 0.8598, 0.5881, 0.8166, 0.8223, 0.8203, 0.6427,\n",
      "        0.8095, 0.7481, 0.8100, 0.7256, 0.8412, 0.6942, 0.8501, 0.7083, 0.8855,\n",
      "        0.6514, 0.8219, 0.7505, 0.8457, 0.7931, 0.8283, 0.7013, 0.8189, 0.6632,\n",
      "        0.8734, 0.7159, 0.8557, 0.6729, 0.8493, 0.6390, 0.8463, 0.7429, 0.8692,\n",
      "        0.6067, 0.8321, 0.6262, 0.8897, 0.6849, 0.8527, 0.6271, 0.8270, 0.7213,\n",
      "        0.8951, 0.7592, 0.8551, 0.6194, 0.8684, 0.7504, 0.8242, 0.7992, 0.8334,\n",
      "        0.7476, 0.8288, 0.7588, 0.8394, 0.6984, 0.8394, 0.7534, 0.8724, 0.7329,\n",
      "        0.8131, 0.6777, 0.8467, 0.8219, 0.8345, 0.6723, 0.8352, 0.7002, 0.8856,\n",
      "        0.7210, 0.8781, 0.6864, 0.8539, 0.7744, 0.8013, 0.7596, 0.8469, 0.6792,\n",
      "        0.8376, 0.6551, 0.8374, 0.6491, 0.8597, 0.6098, 0.8745, 0.6569, 0.8631,\n",
      "        0.7209, 0.8414, 0.6855, 0.8248, 0.6449, 0.8605, 0.7626, 0.8175, 0.6993,\n",
      "        0.8681, 0.6559, 0.8297, 0.6384, 0.8230, 0.6804, 0.8162, 0.6778, 0.8354,\n",
      "        0.7213, 0.8108, 0.8454, 0.9362, 0.6469, 0.8556, 0.7019, 0.8376, 0.8492,\n",
      "        0.8627, 0.8219, 0.8269, 0.6088, 0.7807, 0.6742, 0.8318, 0.6569, 0.8441,\n",
      "        0.6804, 0.8417, 0.6960, 0.8338, 0.7899, 0.8613, 0.7182, 0.8610, 0.7727,\n",
      "        0.8308, 0.6686, 0.8569, 0.8698, 0.8058, 0.6675, 0.8208, 0.6905, 0.7959,\n",
      "        0.6537, 0.8398, 0.7231, 0.8162, 0.6640, 0.8890, 0.6478, 0.8960, 0.6526,\n",
      "        0.7951, 0.9035, 0.8667, 0.7572, 0.8276, 0.6584, 0.8535, 0.7734, 0.7812,\n",
      "        0.6470, 0.8257, 0.7048, 0.8863, 0.6736, 0.8821, 0.7080, 0.8481, 0.6160,\n",
      "        0.7769, 0.8346, 0.8382, 0.8311, 0.8678, 0.6971, 0.8447, 0.8430, 0.8665,\n",
      "        0.6461, 0.8428, 0.6078, 0.8114, 0.6218, 0.8420, 0.5938, 0.8449, 0.6671,\n",
      "        0.8257, 0.8292, 0.8609, 0.6964, 0.8348, 0.6225, 0.8555, 0.7682, 0.8428,\n",
      "        0.8668, 0.8030, 0.6107, 0.8444, 0.7215, 0.8109, 0.6122, 0.8342, 0.6554,\n",
      "        0.8199, 0.6096, 0.8146, 0.7451], requires_grad=True)\n",
      "name is transformer.h.0.attn.c_attn.weight, params is Parameter containing:\n",
      "tensor([[ 0.0119, -0.0064,  0.0342,  ..., -0.0037,  0.0410,  0.0576],\n",
      "        [ 0.0065,  0.0036, -0.0359,  ...,  0.0145, -0.0138,  0.0080],\n",
      "        [-0.0337, -0.0129, -0.0203,  ...,  0.0137, -0.0170, -0.0091],\n",
      "        ...,\n",
      "        [-0.0266,  0.0083, -0.0021,  ...,  0.0066, -0.0091, -0.0233],\n",
      "        [ 0.0104, -0.0114,  0.0211,  ..., -0.0002, -0.0121,  0.0123],\n",
      "        [ 0.0249, -0.0007,  0.0325,  ...,  0.0103,  0.0104, -0.0020]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.0.attn.c_proj.weight, params is Parameter containing:\n",
      "tensor([[ 0.0114,  0.0006,  0.0065,  ..., -0.0132,  0.0132, -0.0108],\n",
      "        [-0.0123,  0.0125, -0.0006,  ..., -0.0261,  0.0190,  0.0231],\n",
      "        [ 0.0003,  0.0132,  0.0068,  ...,  0.0062,  0.0057, -0.0149],\n",
      "        ...,\n",
      "        [ 0.0105,  0.0301, -0.0131,  ..., -0.0165, -0.0172,  0.0014],\n",
      "        [-0.0033, -0.0150, -0.0023,  ...,  0.0028,  0.0102,  0.0108],\n",
      "        [-0.0045, -0.0059,  0.0069,  ...,  0.0176,  0.0007,  0.0061]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.0.ln_2.weight, params is Parameter containing:\n",
      "tensor([1.0696, 0.8245, 1.0996, 0.6571, 0.9872, 0.7323, 1.0010, 0.7010, 1.0669,\n",
      "        0.6736, 0.9878, 0.8836, 1.0561, 0.9408, 1.1062, 0.6853, 1.0130, 0.7116,\n",
      "        1.0518, 0.9018, 1.1211, 0.7299, 1.0377, 0.7113, 1.0037, 0.7765, 1.0007,\n",
      "        0.7307, 1.0060, 0.9673, 1.0543, 0.8255, 1.0764, 0.7172, 1.0603, 0.7937,\n",
      "        1.0689, 0.8536, 1.0623, 0.7273, 1.0819, 0.7409, 1.0988, 0.7223, 1.1141,\n",
      "        0.7211, 1.0248, 0.9228, 1.0719, 0.6568, 1.0734, 0.6814, 1.0508, 0.6813,\n",
      "        1.0030, 0.9350, 1.0691, 0.8757, 1.0460, 0.7374, 1.1144, 0.6874, 1.0417,\n",
      "        0.8084, 1.0658, 0.7872, 1.0834, 0.6892, 1.0113, 0.6746, 1.0787, 0.7451,\n",
      "        1.1384, 0.7915, 0.9793, 0.6813, 1.0709, 0.7868, 1.0224, 0.6640, 1.0984,\n",
      "        0.6960, 1.1038, 0.6942, 1.1098, 0.7398, 1.0987, 0.6671, 1.1123, 0.9947,\n",
      "        1.0417, 0.7990, 1.0399, 0.6549, 1.0145, 0.8540, 1.0772, 0.9032, 1.0828,\n",
      "        0.8509, 1.0012, 0.8962, 1.0392, 0.7864, 1.0610, 0.7161, 1.0661, 0.6381,\n",
      "        1.0749, 0.7315, 1.0744, 0.7357, 1.0722, 0.7559, 1.0152, 0.7309, 1.0100,\n",
      "        0.7876, 1.0401, 0.7416, 1.0945, 0.7045, 1.0507, 0.7153, 1.0230, 0.7258,\n",
      "        1.0130, 0.6768, 1.0919, 0.7430, 1.0692, 0.7356, 1.0629, 0.8010, 1.0971,\n",
      "        0.9469, 1.0803, 0.8973, 1.0021, 0.7038, 1.0147, 0.7773, 1.0153, 0.7271,\n",
      "        1.0504, 0.7120, 1.0201, 0.7636, 0.9297, 0.6909, 1.0151, 0.7010, 1.0623,\n",
      "        0.6537, 1.1118, 0.8615, 1.0453, 0.7221, 1.0714, 0.7218, 0.9981, 1.0067,\n",
      "        1.0734, 0.7024, 1.0561, 0.6935, 1.0543, 0.8296, 1.0811, 0.6788, 1.0509,\n",
      "        0.7383, 1.0433, 0.7313, 1.0512, 0.7573, 1.1011, 0.7253, 1.0370, 0.7341,\n",
      "        1.0731, 0.6750, 1.0844, 0.9494, 1.0614, 0.7941, 1.0805, 0.6676, 0.9704,\n",
      "        0.7476, 1.0150, 0.9164, 1.0412, 0.7328, 1.0288, 0.7457, 0.9613, 0.7506,\n",
      "        0.9917, 0.8295, 1.1101, 0.7816, 0.9773, 0.6950, 1.0126, 0.7434, 0.9808,\n",
      "        0.7571, 1.0210, 0.7819, 1.0727, 0.8220, 1.0427, 0.6998, 1.0944, 0.6921,\n",
      "        1.0061, 0.9356, 1.0642, 1.0510, 0.9907, 0.7348, 1.0065, 0.9360, 1.0530,\n",
      "        0.6581, 1.0514, 0.6057, 0.9435, 0.7337, 1.0350, 0.6721, 0.9920, 0.7703,\n",
      "        1.0320, 0.6713, 1.0361, 0.8293, 1.0392, 0.7377, 1.0443, 0.7058, 1.0878,\n",
      "        0.8838, 1.0248, 0.6854, 1.0448, 0.6685, 1.0879, 0.6116, 1.0175, 0.6927,\n",
      "        0.9786, 0.6647, 1.0623, 0.7633], requires_grad=True)\n",
      "name is transformer.h.0.mlp.c_fc.weight, params is Parameter containing:\n",
      "tensor([[ 0.0112,  0.0414, -0.0036,  ...,  0.0078,  0.0027, -0.0173],\n",
      "        [ 0.0035,  0.0386,  0.0083,  ...,  0.0253,  0.0169, -0.0181],\n",
      "        [ 0.0103,  0.0066, -0.0110,  ...,  0.0428, -0.0531, -0.0040],\n",
      "        ...,\n",
      "        [ 0.0293,  0.0151, -0.0230,  ..., -0.0125,  0.0178, -0.0031],\n",
      "        [ 0.0037,  0.0029, -0.0518,  ...,  0.0246, -0.0273, -0.0342],\n",
      "        [-0.0511,  0.0004, -0.0084,  ...,  0.0319,  0.0417,  0.0035]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.0.mlp.c_proj.weight, params is Parameter containing:\n",
      "tensor([[-0.0350, -0.0129, -0.0079,  ..., -0.0259,  0.0039, -0.0033],\n",
      "        [ 0.0028, -0.0215,  0.0310,  ...,  0.0426, -0.0028,  0.0476],\n",
      "        [-0.0503,  0.0147,  0.0203,  ..., -0.0201, -0.0210, -0.0328],\n",
      "        ...,\n",
      "        [ 0.0070, -0.0172,  0.0096,  ..., -0.0202,  0.0074, -0.0898],\n",
      "        [ 0.0088, -0.0052,  0.0040,  ..., -0.0165, -0.0208,  0.0563],\n",
      "        [-0.0201, -0.0074, -0.0056,  ...,  0.0217, -0.0321, -0.0307]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.1.ln_1.weight, params is Parameter containing:\n",
      "tensor([0.8116, 0.8180, 0.8324, 0.7060, 0.9580, 0.7868, 0.9582, 0.8128, 0.7891,\n",
      "        0.7541, 0.9539, 0.7523, 0.8680, 0.7481, 0.8253, 0.7875, 0.8844, 0.7847,\n",
      "        0.9547, 0.7165, 0.8229, 0.7695, 0.8457, 0.7596, 0.8496, 0.7803, 0.8652,\n",
      "        0.7864, 0.8994, 0.7569, 0.8279, 0.6897, 0.8435, 0.7348, 0.8642, 0.7452,\n",
      "        0.9083, 0.8035, 0.8664, 0.7672, 0.8649, 0.7542, 0.7876, 0.7730, 0.8780,\n",
      "        0.8151, 0.8113, 0.7733, 0.7907, 0.7957, 0.8461, 0.7951, 0.8494, 0.7405,\n",
      "        0.7784, 0.7901, 0.8791, 0.7981, 0.8010, 0.7739, 0.8117, 0.7939, 0.8978,\n",
      "        0.7591, 0.9194, 0.7404, 0.8656, 0.7803, 0.9957, 0.7075, 0.8115, 0.8035,\n",
      "        0.8051, 0.7565, 0.8875, 0.7497, 0.8621, 0.7789, 0.8839, 0.7499, 0.8275,\n",
      "        0.7723, 0.8374, 0.8005, 0.8346, 0.7191, 0.8383, 0.6808, 0.8699, 0.6970,\n",
      "        0.8883, 0.7553, 0.8101, 0.7877, 0.8892, 0.7808, 0.8294, 0.7717, 0.8116,\n",
      "        0.7668, 0.8590, 0.7673, 0.8724, 0.7722, 0.8836, 0.7681, 0.8650, 0.7530,\n",
      "        0.9109, 0.7090, 0.8325, 0.8096, 0.8632, 0.7639, 0.8993, 0.8162, 0.8474,\n",
      "        0.7440, 0.8606, 0.7961, 0.8437, 0.7757, 0.8300, 0.8042, 0.8625, 0.7754,\n",
      "        0.9250, 0.7646, 0.8473, 0.7848, 0.8594, 0.7216, 0.8424, 0.7949, 0.8969,\n",
      "        0.7699, 0.8337, 0.6953, 0.8881, 0.7676, 0.8517, 0.7882, 0.8487, 0.7786,\n",
      "        0.9628, 0.7691, 0.9335, 0.7620, 0.8668, 0.7614, 0.8868, 0.7823, 0.8724,\n",
      "        0.7961, 0.8364, 0.7431, 0.8680, 0.7805, 0.8194, 0.8182, 0.9117, 0.7952,\n",
      "        0.8396, 0.8662, 0.8703, 0.7793, 0.9269, 0.8048, 0.8866, 0.7486, 0.8615,\n",
      "        0.7523, 0.8493, 0.7943, 0.8211, 0.7912, 0.8226, 0.7851, 0.8571, 0.7560,\n",
      "        0.7927, 0.7665, 0.8147, 0.7943, 0.8566, 0.7867, 0.8600, 0.7664, 0.8998,\n",
      "        0.7609, 0.9022, 0.7806, 0.8388, 0.7597, 0.8461, 0.7709, 0.9578, 0.7466,\n",
      "        0.8553, 0.6557, 0.8752, 0.8146, 0.8578, 0.7759, 0.8587, 0.7545, 0.7958,\n",
      "        0.7329, 0.9120, 0.7440, 0.8777, 0.7593, 0.8731, 0.7609, 0.9377, 0.7703,\n",
      "        0.9204, 0.7594, 0.8444, 0.7779, 1.0016, 0.7712, 0.9215, 0.7801, 0.8751,\n",
      "        0.7495, 0.8462, 0.7953, 0.9109, 0.7233, 0.9140, 0.7768, 0.8624, 0.7443,\n",
      "        0.8770, 0.8138, 0.8616, 0.7914, 0.9225, 0.7727, 0.8549, 0.7728, 0.8765,\n",
      "        0.7368, 0.9306, 0.8045, 0.8557, 0.7649, 0.8487, 0.7495, 0.9421, 0.7323,\n",
      "        0.9404, 0.7313, 0.8810, 0.7656], requires_grad=True)\n",
      "name is transformer.h.1.attn.c_attn.weight, params is Parameter containing:\n",
      "tensor([[ 0.0170, -0.0039, -0.0095,  ..., -0.0414, -0.0307,  0.0133],\n",
      "        [ 0.0010, -0.0021, -0.0597,  ...,  0.0070, -0.0357,  0.0331],\n",
      "        [ 0.0115, -0.0047, -0.0502,  ...,  0.0296, -0.0320, -0.0086],\n",
      "        ...,\n",
      "        [-0.0106,  0.0086, -0.0237,  ..., -0.0144,  0.0147, -0.0118],\n",
      "        [ 0.0116, -0.0402, -0.0006,  ...,  0.0143,  0.0225, -0.0088],\n",
      "        [-0.0115, -0.0229,  0.0135,  ..., -0.0273, -0.0076,  0.0286]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.1.attn.c_proj.weight, params is Parameter containing:\n",
      "tensor([[-0.0359, -0.0257,  0.0061,  ..., -0.0222,  0.0350,  0.0021],\n",
      "        [-0.0071, -0.0025, -0.0257,  ...,  0.0087, -0.0017, -0.0019],\n",
      "        [-0.0189,  0.0121,  0.0041,  ...,  0.0036,  0.0238, -0.0093],\n",
      "        ...,\n",
      "        [ 0.0189,  0.0110, -0.0123,  ...,  0.0056, -0.0287,  0.0258],\n",
      "        [-0.0092, -0.0157, -0.0110,  ...,  0.0119, -0.0259, -0.0045],\n",
      "        [-0.0013,  0.0094, -0.0097,  ...,  0.0094,  0.0004,  0.0025]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.1.ln_2.weight, params is Parameter containing:\n",
      "tensor([1.1054, 0.8736, 1.1168, 0.8734, 1.1872, 0.8553, 1.1920, 0.9667, 1.1332,\n",
      "        0.9111, 1.1650, 0.9711, 1.1220, 0.8448, 1.1446, 0.9218, 1.1575, 0.9052,\n",
      "        1.1781, 0.9023, 1.1269, 0.8840, 1.1143, 0.9873, 1.1825, 0.9191, 1.1601,\n",
      "        1.0087, 1.1481, 0.8601, 1.1446, 0.9994, 1.1457, 0.9435, 1.1409, 1.0256,\n",
      "        1.1721, 0.8608, 1.1557, 0.9010, 1.1420, 0.9215, 1.1193, 0.8922, 1.0995,\n",
      "        0.8546, 1.1346, 0.9288, 1.1102, 0.8438, 1.1747, 0.9522, 1.1598, 0.9588,\n",
      "        1.1721, 0.9085, 1.1496, 0.8451, 1.1611, 0.9536, 1.1416, 0.9560, 1.1299,\n",
      "        0.8424, 1.1454, 0.8746, 1.1419, 0.9113, 1.1318, 0.9403, 1.1558, 0.9530,\n",
      "        1.1417, 0.9502, 1.1018, 0.9898, 1.1233, 0.8948, 1.0816, 0.8512, 1.1353,\n",
      "        0.9258, 1.1107, 0.9254, 1.1668, 0.8503, 1.1438, 0.9288, 1.2008, 0.9234,\n",
      "        1.1362, 0.8778, 1.0898, 0.9084, 1.1703, 0.8793, 1.1033, 0.8771, 1.1628,\n",
      "        0.8825, 1.1456, 0.8721, 1.1524, 0.9393, 1.1306, 0.8888, 1.1211, 0.9267,\n",
      "        1.1949, 0.8472, 1.1080, 0.9388, 1.1056, 0.9011, 1.1917, 0.9120, 1.0996,\n",
      "        0.8635, 1.1602, 0.8596, 1.1587, 0.9074, 1.1213, 0.9329, 1.1383, 0.9314,\n",
      "        1.1905, 0.9427, 1.1275, 0.9576, 1.0878, 0.9359, 1.1295, 0.8307, 1.1134,\n",
      "        0.8407, 1.0948, 0.8847, 1.1855, 0.9297, 1.1440, 0.9688, 1.1319, 0.9028,\n",
      "        1.2330, 0.9355, 1.1971, 0.8916, 1.1541, 0.8658, 1.0964, 0.9108, 1.2145,\n",
      "        0.9043, 1.1434, 0.9816, 1.1543, 1.0056, 1.1563, 0.8454, 1.1703, 0.8377,\n",
      "        1.1575, 0.9122, 1.1633, 0.8515, 1.1802, 0.8698, 1.1458, 0.8749, 1.1216,\n",
      "        0.8429, 1.1101, 0.9095, 1.1119, 0.8499, 1.1570, 0.9155, 1.1618, 0.9724,\n",
      "        1.1351, 0.9039, 1.1458, 0.9053, 1.1557, 0.8445, 1.2667, 0.8736, 1.1427,\n",
      "        0.8888, 1.1351, 0.9152, 1.1508, 0.9134, 1.1465, 0.9824, 1.0834, 1.0574,\n",
      "        1.1268, 1.0010, 1.1328, 0.9601, 1.1696, 0.8896, 1.1376, 0.9471, 1.1022,\n",
      "        0.9051, 1.1550, 0.8954, 1.1486, 0.8413, 1.1124, 0.9431, 1.2422, 0.8698,\n",
      "        1.1999, 0.9062, 1.1741, 0.8822, 1.1239, 0.8916, 1.1526, 0.8962, 1.1035,\n",
      "        0.9029, 1.1099, 0.9368, 1.1438, 0.9253, 1.1913, 0.9233, 1.1820, 0.9344,\n",
      "        1.1674, 0.8722, 1.1362, 0.9246, 1.2481, 0.8815, 1.1248, 0.8658, 1.1359,\n",
      "        0.9757, 1.1360, 0.9301, 1.1097, 0.9107, 1.1479, 0.8163, 1.1655, 0.9369,\n",
      "        1.1298, 0.9125, 1.1701, 0.8857], requires_grad=True)\n",
      "name is transformer.h.1.mlp.c_fc.weight, params is Parameter containing:\n",
      "tensor([[ 0.0152, -0.0408,  0.0116,  ..., -0.0279,  0.0567,  0.0023],\n",
      "        [-0.0701,  0.0132, -0.0261,  ...,  0.0302,  0.0351, -0.0139],\n",
      "        [-0.0018,  0.0553, -0.1311,  ...,  0.0778, -0.0647, -0.0169],\n",
      "        ...,\n",
      "        [-0.0165, -0.0237, -0.0565,  ...,  0.0253,  0.0142, -0.0419],\n",
      "        [-0.0102, -0.0004,  0.0286,  ..., -0.0646, -0.0153, -0.0136],\n",
      "        [-0.0288,  0.0067, -0.0531,  ...,  0.0635, -0.0136,  0.0100]],\n",
      "       requires_grad=True)\n",
      "name is transformer.h.1.mlp.c_proj.weight, params is Parameter containing:\n",
      "tensor([[-0.0229, -0.0104, -0.0278,  ..., -0.0222, -0.0103,  0.0047],\n",
      "        [-0.0600,  0.0261,  0.0455,  ..., -0.0024,  0.0096,  0.0075],\n",
      "        [ 0.0308,  0.0354,  0.0031,  ..., -0.0166, -0.0425, -0.0151],\n",
      "        ...,\n",
      "        [ 0.0186, -0.0344,  0.0061,  ..., -0.0140,  0.0154,  0.0020],\n",
      "        [ 0.0183,  0.0383, -0.0500,  ...,  0.0241, -0.0383,  0.0220],\n",
      "        [ 0.0408,  0.0275, -0.0157,  ..., -0.0047, -0.0646, -0.0217]],\n",
      "       requires_grad=True)\n",
      "name is transformer.ln_f.weight, params is Parameter containing:\n",
      "tensor([1.1105, 1.1642, 1.1493, 1.1269, 1.4128, 1.1160, 1.1509, 1.1378, 1.1357,\n",
      "        1.1365, 1.4016, 1.1477, 1.1938, 1.1287, 1.1770, 1.1403, 1.2133, 1.1504,\n",
      "        1.2746, 1.1350, 1.1434, 1.1542, 1.1590, 1.1639, 1.2684, 1.1254, 1.1956,\n",
      "        1.1745, 1.1089, 1.1685, 1.1828, 1.1389, 1.1938, 1.1746, 1.1447, 1.1446,\n",
      "        1.1669, 1.1095, 1.2365, 1.1797, 1.1606, 1.1321, 1.1623, 1.1497, 1.1895,\n",
      "        1.1601, 1.1676, 1.1512, 1.1625, 1.1068, 1.2056, 1.1742, 1.1668, 1.1584,\n",
      "        1.1793, 1.1266, 1.1282, 1.1649, 1.2113, 1.2088, 1.2046, 1.1381, 1.1411,\n",
      "        1.1246, 1.1553, 1.0811, 1.1670, 1.1890, 1.2472, 1.1402, 1.1395, 1.1573,\n",
      "        1.1804, 1.1644, 1.2186, 1.1226, 1.4093, 1.1408, 1.1129, 1.1053, 1.1862,\n",
      "        1.1486, 1.1636, 1.1446, 1.1659, 1.1377, 1.1454, 1.1208, 1.2404, 1.1568,\n",
      "        1.1666, 1.1597, 1.1468, 1.1437, 1.2155, 1.1485, 1.1534, 1.1386, 1.2465,\n",
      "        1.1135, 1.1594, 1.1488, 1.1538, 1.1398, 1.1580, 1.1344, 1.1281, 1.1408,\n",
      "        1.1698, 1.1154, 1.1570, 1.1786, 1.1233, 1.1370, 1.2703, 1.1672, 1.1572,\n",
      "        1.1217, 1.3547, 1.1041, 1.1897, 1.1833, 1.1669, 1.1605, 1.1865, 1.1455,\n",
      "        1.1675, 1.1384, 1.1478, 1.1628, 1.1156, 1.1272, 1.1643, 1.1610, 1.1692,\n",
      "        1.1215, 1.1470, 1.1405, 1.2670, 1.1720, 1.1402, 1.1805, 1.1514, 1.1295,\n",
      "        1.4284, 1.1429, 1.3129, 1.1464, 1.2208, 1.1345, 1.1547, 1.1535, 1.3373,\n",
      "        1.1325, 1.1970, 1.1416, 1.1937, 1.1529, 1.1427, 1.1227, 1.2114, 1.1369,\n",
      "        1.1912, 1.1600, 1.1710, 1.1122, 1.2624, 1.1259, 1.1403, 1.1451, 1.1754,\n",
      "        1.0698, 1.1639, 1.1257, 1.1628, 1.1790, 1.1700, 1.1305, 1.1516, 1.1540,\n",
      "        1.1332, 1.1846, 1.1679, 1.1406, 1.1928, 1.1298, 1.3489, 1.1063, 1.2360,\n",
      "        1.1416, 1.1445, 1.1617, 1.1363, 1.1639, 1.2025, 1.1089, 1.2341, 1.1946,\n",
      "        1.1586, 1.1533, 1.1688, 1.1771, 1.1784, 1.1625, 1.1946, 1.1550, 1.1732,\n",
      "        1.1358, 1.1488, 1.1470, 1.1423, 1.1281, 1.1495, 1.1891, 1.1970, 1.1621,\n",
      "        1.3651, 1.1391, 1.1926, 1.1452, 1.2450, 1.1446, 1.1624, 1.1530, 1.1682,\n",
      "        1.1390, 1.1655, 1.1247, 1.2198, 1.1138, 1.1675, 1.1687, 1.1955, 1.1415,\n",
      "        1.1948, 1.1400, 1.1930, 1.1584, 1.3462, 1.1193, 1.1799, 1.1557, 1.1926,\n",
      "        1.1358, 1.1963, 1.1537, 1.2006, 1.1234, 1.1420, 1.1313, 1.2221, 1.1367,\n",
      "        1.1420, 1.1404, 1.1885, 1.1400], requires_grad=True)\n",
      "name is lm_head.weight, params is Parameter containing:\n",
      "tensor([[ 0.0308, -0.1153,  0.0024,  ..., -0.0620, -0.0039,  0.0384],\n",
      "        [-0.0409, -0.0783,  0.0179,  ...,  0.0353,  0.0409, -0.0172],\n",
      "        [ 0.0071, -0.0557,  0.0484,  ...,  0.0017,  0.0496,  0.0190],\n",
      "        ...,\n",
      "        [-0.0205, -0.0322,  0.0507,  ...,  0.0243, -0.0623,  0.0082],\n",
      "        [ 0.0254, -0.0002,  0.0074,  ..., -0.0021,  0.0216, -0.0081],\n",
      "        [-0.0267,  0.0636,  0.0277,  ..., -0.0583,  0.0573,  0.0228]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# model\n",
    "if init_from == 'resume':\n",
    "    # init from a model saved in a specific directory\n",
    "    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "    model = GPT(gptconf)\n",
    "    state_dict = checkpoint['model']\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# look for the meta pickle in case it is available in the dataset folder\n",
    "load_meta = False\n",
    "\n",
    "if init_from == 'resume' and 'config' in checkpoint and 'dataset' in checkpoint['config']: # older checkpoints might not have these...\n",
    "    meta_path = os.path.join('data', checkpoint['config']['dataset'], 'meta.pkl')\n",
    "    load_meta = os.path.exists(meta_path)\n",
    "\n",
    "\n",
    "print(f\"Loading meta from {meta_path}...\")\n",
    "# meta数据\n",
    "meta = {}\n",
    "with open(meta_path, 'r') as f:\n",
    "    meta = json.load(f)\n",
    "def decode(id):\n",
    "    return meta['itos'][str(id)]\n",
    "\n",
    "\n",
    "\n",
    "for name, params in model.named_parameters():\n",
    "    print(f'name is {name}, params is {params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_date</th>\n",
       "      <th>000001.SZ_amount_chg</th>\n",
       "      <th>000001.SZ_close_chg</th>\n",
       "      <th>000002.SZ_amount_chg</th>\n",
       "      <th>000002.SZ_close_chg</th>\n",
       "      <th>000004.SZ_amount_chg</th>\n",
       "      <th>000004.SZ_close_chg</th>\n",
       "      <th>000005.SZ_amount_chg</th>\n",
       "      <th>000005.SZ_close_chg</th>\n",
       "      <th>000006.SZ_amount_chg</th>\n",
       "      <th>...</th>\n",
       "      <th>600308.SH_amount_chg</th>\n",
       "      <th>600308.SH_close_chg</th>\n",
       "      <th>600309.SH_amount_chg</th>\n",
       "      <th>600309.SH_close_chg</th>\n",
       "      <th>600310.SH_amount_chg</th>\n",
       "      <th>600310.SH_close_chg</th>\n",
       "      <th>600312.SH_amount_chg</th>\n",
       "      <th>600312.SH_close_chg</th>\n",
       "      <th>600313.SH_amount_chg</th>\n",
       "      <th>600313.SH_close_chg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>20220718</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0113</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>1.0159</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>1.0206</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>1.0178</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>1.0351</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>1.0263</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0447</td>\n",
       "      <td>1.1879</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>1.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>20220719</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>0.7406</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>1.4858</td>\n",
       "      <td>1.0498</td>\n",
       "      <td>0.8352</td>\n",
       "      <td>1.0058</td>\n",
       "      <td>0.8210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>1.0196</td>\n",
       "      <td>1.1213</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.6814</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>1.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>20220720</td>\n",
       "      <td>1.0648</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>1.8017</td>\n",
       "      <td>1.0289</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7370</td>\n",
       "      <td>1.0018</td>\n",
       "      <td>1.4763</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>3.3033</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>1.0176</td>\n",
       "      <td>1.2722</td>\n",
       "      <td>0.9754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>20220721</td>\n",
       "      <td>2.4105</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.8964</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2638</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.7819</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>1.5606</td>\n",
       "      <td>0.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>20220722</td>\n",
       "      <td>0.6782</td>\n",
       "      <td>1.0023</td>\n",
       "      <td>0.6094</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>1.0971</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>1.1409</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>1.0199</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5856</td>\n",
       "      <td>0.9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>20220725</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>1.0008</td>\n",
       "      <td>1.1398</td>\n",
       "      <td>1.0069</td>\n",
       "      <td>1.4092</td>\n",
       "      <td>1.0299</td>\n",
       "      <td>1.5147</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>1.6166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9516</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9683</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.9704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>20220726</td>\n",
       "      <td>1.3465</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>1.7431</td>\n",
       "      <td>1.0314</td>\n",
       "      <td>1.0538</td>\n",
       "      <td>1.0194</td>\n",
       "      <td>1.4805</td>\n",
       "      <td>1.0278</td>\n",
       "      <td>1.4481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>1.0069</td>\n",
       "      <td>0.9128</td>\n",
       "      <td>1.0059</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0206</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>1.0153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>20220727</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.5136</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.6145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0288</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>1.7681</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>1.2788</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>1.0537</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>1.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>20220728</td>\n",
       "      <td>0.8157</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>1.0444</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>1.0163</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>1.1170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>1.0378</td>\n",
       "      <td>1.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>20220729</td>\n",
       "      <td>1.0981</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>1.2584</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.6268</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>1.1437</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1366</td>\n",
       "      <td>0.9932</td>\n",
       "      <td>1.4044</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>1.5111</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.9515</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.2109</td>\n",
       "      <td>0.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>20220801</td>\n",
       "      <td>1.2062</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.8885</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.6963</td>\n",
       "      <td>1.0043</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.6971</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>1.2807</td>\n",
       "      <td>0.9805</td>\n",
       "      <td>0.5912</td>\n",
       "      <td>0.9857</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>1.0726</td>\n",
       "      <td>0.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>20220802</td>\n",
       "      <td>1.3024</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>1.9103</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>2.2694</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>2.2568</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1447</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>1.5597</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>2.6347</td>\n",
       "      <td>1.0609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>20220803</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.9812</td>\n",
       "      <td>1.1719</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>1.0046</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.5852</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>1.0401</td>\n",
       "      <td>1.0050</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>0.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>20220804</td>\n",
       "      <td>0.8053</td>\n",
       "      <td>1.0108</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>1.0106</td>\n",
       "      <td>1.2120</td>\n",
       "      <td>1.0498</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>1.0233</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>1.0312</td>\n",
       "      <td>1.7062</td>\n",
       "      <td>1.0613</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>0.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>20220805</td>\n",
       "      <td>1.2763</td>\n",
       "      <td>1.0123</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>1.0142</td>\n",
       "      <td>2.3975</td>\n",
       "      <td>1.0216</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>1.0216</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>1.0202</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9312</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>1.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>20220808</td>\n",
       "      <td>0.7251</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>1.5771</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.7077</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5798</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>1.1464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.2142</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>1.0987</td>\n",
       "      <td>1.0121</td>\n",
       "      <td>0.7479</td>\n",
       "      <td>1.0343</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>1.0097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>20220809</td>\n",
       "      <td>1.0032</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.6548</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>1.3960</td>\n",
       "      <td>1.0113</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>1.4205</td>\n",
       "      <td>1.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>20220810</td>\n",
       "      <td>1.2196</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>1.0156</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>3.0479</td>\n",
       "      <td>1.0388</td>\n",
       "      <td>0.9810</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>1.0151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6330</td>\n",
       "      <td>1.0088</td>\n",
       "      <td>1.1912</td>\n",
       "      <td>1.0023</td>\n",
       "      <td>1.1929</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>1.0072</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>20220811</td>\n",
       "      <td>2.0716</td>\n",
       "      <td>1.0240</td>\n",
       "      <td>1.4663</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>0.5616</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>2.0679</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>1.1569</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1623</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>1.2957</td>\n",
       "      <td>1.0187</td>\n",
       "      <td>1.3258</td>\n",
       "      <td>1.0245</td>\n",
       "      <td>1.6381</td>\n",
       "      <td>1.0285</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>1.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>20220812</td>\n",
       "      <td>0.5908</td>\n",
       "      <td>1.0024</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>1.0061</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4637</td>\n",
       "      <td>1.0086</td>\n",
       "      <td>2.4987</td>\n",
       "      <td>1.0544</td>\n",
       "      <td>1.1116</td>\n",
       "      <td>1.0149</td>\n",
       "      <td>0.6248</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>1.4126</td>\n",
       "      <td>1.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>20220815</td>\n",
       "      <td>1.4101</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>1.0060</td>\n",
       "      <td>1.0207</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>1.0020</td>\n",
       "      <td>1.3808</td>\n",
       "      <td>1.0235</td>\n",
       "      <td>1.3908</td>\n",
       "      <td>1.0245</td>\n",
       "      <td>1.9081</td>\n",
       "      <td>1.0375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>20220816</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>1.0016</td>\n",
       "      <td>1.5743</td>\n",
       "      <td>1.0147</td>\n",
       "      <td>1.0491</td>\n",
       "      <td>1.0314</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.1944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8138</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>1.7409</td>\n",
       "      <td>1.0374</td>\n",
       "      <td>1.4174</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>0.6964</td>\n",
       "      <td>1.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>20220817</td>\n",
       "      <td>2.1634</td>\n",
       "      <td>1.0223</td>\n",
       "      <td>1.2023</td>\n",
       "      <td>1.0212</td>\n",
       "      <td>1.1822</td>\n",
       "      <td>0.9774</td>\n",
       "      <td>1.7327</td>\n",
       "      <td>1.0166</td>\n",
       "      <td>0.7191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6748</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>1.0464</td>\n",
       "      <td>1.0166</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>1.0181</td>\n",
       "      <td>2.3703</td>\n",
       "      <td>1.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>20220818</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.6757</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2959</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.6013</td>\n",
       "      <td>0.9682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>20220819</td>\n",
       "      <td>1.7003</td>\n",
       "      <td>1.0261</td>\n",
       "      <td>1.1343</td>\n",
       "      <td>1.0131</td>\n",
       "      <td>0.7858</td>\n",
       "      <td>1.0062</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>1.0355</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1849</td>\n",
       "      <td>1.0105</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>1.4928</td>\n",
       "      <td>1.0222</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>1.2349</td>\n",
       "      <td>1.0204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>20220822</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>1.0024</td>\n",
       "      <td>1.1824</td>\n",
       "      <td>1.0297</td>\n",
       "      <td>2.0380</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>3.0621</td>\n",
       "      <td>1.0528</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>1.2392</td>\n",
       "      <td>1.0504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>20220823</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>1.1392</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.7642</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0118</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>1.0192</td>\n",
       "      <td>1.3997</td>\n",
       "      <td>1.0204</td>\n",
       "      <td>1.0131</td>\n",
       "      <td>1.0372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>20220824</td>\n",
       "      <td>1.4185</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>1.0179</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>1.4834</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>1.6492</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7204</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.6873</td>\n",
       "      <td>0.9793</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>1.1450</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>1.4850</td>\n",
       "      <td>1.0367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>20220825</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.1537</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>0.7890</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.7917</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>2.3579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7136</td>\n",
       "      <td>1.0071</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>1.0055</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.7809</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>20220826</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.2622</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.7519</td>\n",
       "      <td>1.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>20220829</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>1.0183</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>1.1592</td>\n",
       "      <td>1.0055</td>\n",
       "      <td>0.5920</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3225</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>1.6346</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>1.0559</td>\n",
       "      <td>1.0085</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>1.0130</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>0.9811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>20220830</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>1.0048</td>\n",
       "      <td>0.9015</td>\n",
       "      <td>1.0206</td>\n",
       "      <td>1.4606</td>\n",
       "      <td>1.0182</td>\n",
       "      <td>1.2510</td>\n",
       "      <td>1.0109</td>\n",
       "      <td>1.3835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>1.0071</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>1.0074</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>1.5089</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>1.1465</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>20220831</td>\n",
       "      <td>2.1094</td>\n",
       "      <td>1.0216</td>\n",
       "      <td>2.8437</td>\n",
       "      <td>1.0466</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.7948</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>1.2473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>1.4603</td>\n",
       "      <td>1.0014</td>\n",
       "      <td>1.1665</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>1.4021</td>\n",
       "      <td>0.9467</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>20220901</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>1.0126</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>1.2022</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>1.8657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.5007</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>1.1301</td>\n",
       "      <td>1.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>20220902</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.5261</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>1.0812</td>\n",
       "      <td>1.0140</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>1.0144</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>1.2333</td>\n",
       "      <td>1.0208</td>\n",
       "      <td>1.0342</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>0.6579</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>20220905</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>1.0048</td>\n",
       "      <td>1.3677</td>\n",
       "      <td>1.0220</td>\n",
       "      <td>0.7699</td>\n",
       "      <td>1.0021</td>\n",
       "      <td>2.8757</td>\n",
       "      <td>1.0221</td>\n",
       "      <td>1.5260</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3213</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>1.5452</td>\n",
       "      <td>1.0196</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>1.0145</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>1.0026</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081</th>\n",
       "      <td>20220906</td>\n",
       "      <td>1.1601</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>1.5860</td>\n",
       "      <td>1.0396</td>\n",
       "      <td>1.0933</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>1.0108</td>\n",
       "      <td>1.2353</td>\n",
       "      <td>...</td>\n",
       "      <td>4.7769</td>\n",
       "      <td>1.0439</td>\n",
       "      <td>1.6422</td>\n",
       "      <td>1.0321</td>\n",
       "      <td>1.4789</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>1.3013</td>\n",
       "      <td>1.0274</td>\n",
       "      <td>1.3264</td>\n",
       "      <td>1.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>20220907</td>\n",
       "      <td>1.3210</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.9815</td>\n",
       "      <td>1.2577</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>1.0053</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>1.4020</td>\n",
       "      <td>1.0223</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>1.0076</td>\n",
       "      <td>1.2618</td>\n",
       "      <td>1.0223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>20220908</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>1.0024</td>\n",
       "      <td>0.8159</td>\n",
       "      <td>1.0034</td>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7878</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>1.0302</td>\n",
       "      <td>1.0165</td>\n",
       "      <td>1.2732</td>\n",
       "      <td>1.0054</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.9937</td>\n",
       "      <td>0.8445</td>\n",
       "      <td>0.9548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>20220909</td>\n",
       "      <td>3.2112</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>2.0194</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>1.0088</td>\n",
       "      <td>0.9003</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.6515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>1.7811</td>\n",
       "      <td>1.0391</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>1.0548</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.6752</td>\n",
       "      <td>0.9816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>20220913</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>1.0181</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>1.4342</td>\n",
       "      <td>1.0174</td>\n",
       "      <td>1.2769</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0241</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.7847</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>1.1242</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>1.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>20220914</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.6946</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>1.2109</td>\n",
       "      <td>1.0021</td>\n",
       "      <td>1.5573</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>1.2397</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>1.1480</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3087</th>\n",
       "      <td>20220915</td>\n",
       "      <td>2.1855</td>\n",
       "      <td>1.0212</td>\n",
       "      <td>2.0805</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>4.7932</td>\n",
       "      <td>1.0503</td>\n",
       "      <td>1.1828</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>1.6331</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3258</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>1.0015</td>\n",
       "      <td>1.0249</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>2.5633</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>0.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>20220916</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.5867</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>1.2617</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>1.0338</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1719</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.8691</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>1.2615</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.5638</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.7850</td>\n",
       "      <td>0.9896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>20220919</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>1.0008</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.4779</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.9837</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>1.0108</td>\n",
       "      <td>0.5807</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>0.9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>20220920</td>\n",
       "      <td>1.3891</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>1.1849</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.4811</td>\n",
       "      <td>1.0155</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>1.0817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5790</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>1.0130</td>\n",
       "      <td>1.1743</td>\n",
       "      <td>1.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>20220921</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>1.0073</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0628</td>\n",
       "      <td>1.0036</td>\n",
       "      <td>1.6079</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>1.1462</td>\n",
       "      <td>1.0217</td>\n",
       "      <td>1.2484</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>2.1415</td>\n",
       "      <td>1.0312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>20220922</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>0.8179</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0670</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>0.5891</td>\n",
       "      <td>1.0013</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>1.0042</td>\n",
       "      <td>1.6762</td>\n",
       "      <td>1.0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>20220923</td>\n",
       "      <td>1.0037</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0635</td>\n",
       "      <td>1.0011</td>\n",
       "      <td>2.0674</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>1.3783</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>1.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>1.0859</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>20220926</td>\n",
       "      <td>1.5138</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>1.1073</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.5234</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>1.8206</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.8272</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1749</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>1.3586</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.0629</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>0.9340</td>\n",
       "      <td>0.9321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trade_date  000001.SZ_amount_chg  000001.SZ_close_chg  \\\n",
       "3045    20220718                0.7179               1.0113   \n",
       "3046    20220719                0.6565               1.0022   \n",
       "3047    20220720                1.0648               0.9978   \n",
       "3048    20220721                2.4105               0.9716   \n",
       "3049    20220722                0.6782               1.0023   \n",
       "3050    20220725                0.5560               1.0008   \n",
       "3051    20220726                1.3465               1.0070   \n",
       "3052    20220727                0.9000               0.9907   \n",
       "3053    20220728                0.8157               1.0070   \n",
       "3054    20220729                1.0981               0.9845   \n",
       "3055    20220801                1.2062               0.9795   \n",
       "3056    20220802                1.3024               0.9871   \n",
       "3057    20220803                0.5441               0.9812   \n",
       "3058    20220804                0.8053               1.0108   \n",
       "3059    20220805                1.2763               1.0123   \n",
       "3060    20220808                0.7251               0.9911   \n",
       "3061    20220809                1.0032               0.9934   \n",
       "3062    20220810                1.2196               0.9951   \n",
       "3063    20220811                2.0716               1.0240   \n",
       "3064    20220812                0.5908               1.0024   \n",
       "3065    20220815                1.4101               0.9782   \n",
       "3066    20220816                0.5374               1.0016   \n",
       "3067    20220817                2.1634               1.0223   \n",
       "3068    20220818                0.9419               0.9879   \n",
       "3069    20220819                1.7003               1.0261   \n",
       "3070    20220822                0.5364               0.9944   \n",
       "3071    20220823                0.7990               0.9872   \n",
       "3072    20220824                1.4185               1.0049   \n",
       "3073    20220825                0.8239               1.0177   \n",
       "3074    20220826                0.8794               0.9992   \n",
       "3075    20220829                0.9797               0.9849   \n",
       "3076    20220830                0.8658               1.0048   \n",
       "3077    20220831                2.1094               1.0216   \n",
       "3078    20220901                0.5225               0.9890   \n",
       "3079    20220902                0.9000               0.9921   \n",
       "3080    20220905                0.8017               1.0048   \n",
       "3081    20220906                1.1601               0.9944   \n",
       "3082    20220907                1.3210               0.9864   \n",
       "3083    20220908                0.6363               1.0024   \n",
       "3084    20220909                3.2112               1.0291   \n",
       "3085    20220913                0.9006               1.0181   \n",
       "3086    20220914                0.4924               0.9830   \n",
       "3087    20220915                2.1855               1.0212   \n",
       "3088    20220916                0.7184               0.9662   \n",
       "3089    20220919                0.4615               1.0008   \n",
       "3090    20220920                1.3891               0.9817   \n",
       "3091    20220921                0.7671               1.0073   \n",
       "3092    20220922                0.8517               0.9887   \n",
       "3093    20220923                1.0037               1.0000   \n",
       "3094    20220926                1.5138               0.9764   \n",
       "\n",
       "      000002.SZ_amount_chg  000002.SZ_close_chg  000004.SZ_amount_chg  \\\n",
       "3045                0.6093               1.0159                0.5754   \n",
       "3046                0.7406               0.9944                1.4858   \n",
       "3047                0.8965               0.9977                0.8636   \n",
       "3048                1.8964               0.9735                0.7180   \n",
       "3049                0.6094               1.0052                1.0971   \n",
       "3050                1.1398               1.0069                1.4092   \n",
       "3051                1.7431               1.0314                1.0538   \n",
       "3052                0.5136               0.9839                1.1760   \n",
       "3053                1.0444               0.9938                0.8572   \n",
       "3054                1.2584               0.9751                0.6268   \n",
       "3055                0.8885               0.9802                0.6963   \n",
       "3056                0.9151               0.9793                1.9103   \n",
       "3057                1.1719               0.9722                0.6333   \n",
       "3058                0.4726               1.0106                1.2120   \n",
       "3059                0.9799               1.0142                2.3975   \n",
       "3060                1.5771               0.9885                0.7077   \n",
       "3061                0.6968               0.9975                0.6548   \n",
       "3062                1.0156               0.9920                3.0479   \n",
       "3063                1.4663               1.0112                0.5616   \n",
       "3064                0.8639               1.0061                0.7608   \n",
       "3065                0.9605               0.9945                1.0060   \n",
       "3066                1.5743               1.0147                1.0491   \n",
       "3067                1.2023               1.0212                1.1822   \n",
       "3068                0.6757               0.9947                0.7100   \n",
       "3069                1.1343               1.0131                0.7858   \n",
       "3070                0.7067               1.0024                1.1824   \n",
       "3071                1.1392               0.9889                0.7642   \n",
       "3072                1.0179               0.9858                1.4834   \n",
       "3073                1.1537               1.0115                0.7890   \n",
       "3074                0.8888               1.0000                1.2622   \n",
       "3075                1.0183               0.9836                0.3289   \n",
       "3076                0.9015               1.0206                1.4606   \n",
       "3077                2.8437               1.0466                0.9617   \n",
       "3078                0.8330               1.0126                0.8768   \n",
       "3079                0.5261               0.9976                1.0812   \n",
       "3080                1.3677               1.0220                0.7699   \n",
       "3081                1.5860               1.0396                1.0933   \n",
       "3082                0.6130               0.9815                1.2577   \n",
       "3083                0.8159               1.0034                0.8965   \n",
       "3084                2.0194               1.0324                0.7019   \n",
       "3085                0.7568               1.0017                1.4342   \n",
       "3086                0.6946               0.9851                1.2109   \n",
       "3087                2.0805               1.0329                4.7932   \n",
       "3088                0.7464               0.9730                0.5867   \n",
       "3089                0.7217               1.0100                0.8496   \n",
       "3090                1.1849               0.9659                0.4811   \n",
       "3091                0.7239               1.0000                0.6364   \n",
       "3092                0.8179               0.9960                0.9210   \n",
       "3093                1.0635               1.0011                2.0674   \n",
       "3094                1.1073               0.9960                0.5234   \n",
       "\n",
       "      000004.SZ_close_chg  000005.SZ_amount_chg  000005.SZ_close_chg  \\\n",
       "3045               1.0206                0.8425               1.0178   \n",
       "3046               1.0498                0.8352               1.0058   \n",
       "3047               1.0079                1.8017               1.0289   \n",
       "3048               1.0000                0.6519               1.0056   \n",
       "3049               1.0112                1.1409               1.0000   \n",
       "3050               1.0299                1.5147               1.0056   \n",
       "3051               1.0194                1.4805               1.0278   \n",
       "3052               0.9736                0.6400               0.9946   \n",
       "3053               1.0163                0.6803               0.9946   \n",
       "3054               0.9819                1.1437               1.0000   \n",
       "3055               1.0043                0.6418               0.9891   \n",
       "3056               0.9503                2.2694               0.9503   \n",
       "3057               1.0046                0.6554               1.0000   \n",
       "3058               1.0498                0.9383               1.0233   \n",
       "3059               1.0216                0.7153               0.9943   \n",
       "3060               1.0190                0.5798               1.0114   \n",
       "3061               0.9876                1.3960               1.0113   \n",
       "3062               1.0388                0.9810               0.9832   \n",
       "3063               0.9879                2.0679               1.0114   \n",
       "3064               0.9898                0.7685               1.0056   \n",
       "3065               1.0207                0.7647               1.0112   \n",
       "3066               1.0314                0.9729               1.0000   \n",
       "3067               0.9774                1.7327               1.0166   \n",
       "3068               0.9729                0.7404               0.9891   \n",
       "3069               1.0062                0.9330               1.0110   \n",
       "3070               1.0297                2.0380               1.0272   \n",
       "3071               0.9791                0.8956               0.9894   \n",
       "3072               0.9624                0.8141               0.9840   \n",
       "3073               1.0275                0.7917               0.9946   \n",
       "3074               0.9630                0.6364               1.0000   \n",
       "3075               0.9989                1.1592               1.0055   \n",
       "3076               1.0182                1.2510               1.0109   \n",
       "3077               0.9811                0.7948               0.9839   \n",
       "3078               0.9914                1.2022               0.9836   \n",
       "3079               1.0140                0.6241               1.0056   \n",
       "3080               1.0021                2.8757               1.0221   \n",
       "3081               0.9989                0.5517               1.0108   \n",
       "3082               0.9851                0.9038               1.0053   \n",
       "3083               0.9816                0.7878               0.9947   \n",
       "3084               1.0088                0.9003               1.0000   \n",
       "3085               1.0174                1.2769               1.0000   \n",
       "3086               1.0021                1.5573               1.0000   \n",
       "3087               1.0503                1.1828               0.9893   \n",
       "3088               0.9715                1.2617               0.9568   \n",
       "3089               0.9497                0.4779               0.9887   \n",
       "3090               1.0155                0.4792               1.0114   \n",
       "3091               0.9891                1.6817               1.0056   \n",
       "3092               0.9945                0.7288               0.9944   \n",
       "3093               0.9569                1.3783               1.0056   \n",
       "3094               0.9630                1.8206               0.9494   \n",
       "\n",
       "      000006.SZ_amount_chg  ...  600308.SH_amount_chg  600308.SH_close_chg  \\\n",
       "3045                0.6532  ...                0.8801               1.0351   \n",
       "3046                0.8210  ...                0.9473               1.0196   \n",
       "3047                0.9445  ...                0.7370               1.0018   \n",
       "3048                1.1120  ...                1.2638               1.0000   \n",
       "3049                0.7168  ...                0.9327               1.0070   \n",
       "3050                1.6166  ...                0.9516               1.0017   \n",
       "3051                1.4481  ...                0.8004               1.0069   \n",
       "3052                0.6145  ...                1.0288               1.0051   \n",
       "3053                1.1170  ...                0.9520               0.9966   \n",
       "3054                0.8207  ...                1.1366               0.9932   \n",
       "3055                0.6971  ...                1.0551               0.9914   \n",
       "3056                2.2568  ...                2.1447               0.9704   \n",
       "3057                0.6586  ...                0.5481               0.9928   \n",
       "3058                0.6179  ...                0.9774               1.0054   \n",
       "3059                1.0280  ...                0.9151               1.0216   \n",
       "3060                1.1464  ...                0.6360               1.0000   \n",
       "3061                0.8812  ...                0.7782               1.0000   \n",
       "3062                1.0151  ...                1.6330               1.0088   \n",
       "3063                1.1569  ...                1.1623               1.0087   \n",
       "3064                0.8989  ...                1.4637               1.0086   \n",
       "3065                0.9403  ...                0.5585               0.9897   \n",
       "3066                2.1944  ...                0.8138               0.9983   \n",
       "3067                0.7191  ...                0.8705               1.0000   \n",
       "3068                0.9043  ...                1.2959               0.9913   \n",
       "3069                1.0355  ...                1.1849               1.0105   \n",
       "3070                0.9315  ...                0.9447               0.9983   \n",
       "3071                0.8064  ...                0.8015               1.0000   \n",
       "3072                1.6492  ...                1.7204               0.9809   \n",
       "3073                2.3579  ...                0.7136               1.0071   \n",
       "3074                0.5405  ...                0.7143               0.9947   \n",
       "3075                0.5920  ...                2.3225               0.9965   \n",
       "3076                1.3835  ...                0.9965               1.0071   \n",
       "3077                1.2473  ...                0.8242               0.9806   \n",
       "3078                1.8657  ...                0.7630               0.9946   \n",
       "3079                0.4561  ...                0.7907               1.0144   \n",
       "3080                1.5260  ...                1.3213               1.0125   \n",
       "3081                1.2353  ...                4.7769               1.0439   \n",
       "3082                0.6811  ...                0.6843               0.9781   \n",
       "3083                0.9512  ...                0.5000               0.9914   \n",
       "3084                1.6515  ...                0.8945               1.0087   \n",
       "3085                0.6893  ...                1.0241               0.9966   \n",
       "3086                0.9163  ...                0.7544               0.9879   \n",
       "3087                1.6331  ...                1.3258               1.0000   \n",
       "3088                1.0338  ...                1.1719               0.9668   \n",
       "3089                0.5506  ...                0.7052               0.9837   \n",
       "3090                1.0817  ...                0.5790               1.0110   \n",
       "3091                1.1125  ...                1.0628               1.0036   \n",
       "3092                0.8241  ...                1.0670               0.9946   \n",
       "3093                1.1230  ...                0.9456               0.9873   \n",
       "3094                0.8272  ...                2.1749               0.9465   \n",
       "\n",
       "      600309.SH_amount_chg  600309.SH_close_chg  600310.SH_amount_chg  \\\n",
       "3045                0.6440               1.0263                0.8750   \n",
       "3046                1.1213               0.9863                0.6814   \n",
       "3047                1.4763               0.9844                3.3033   \n",
       "3048                1.0867               0.9766                0.6001   \n",
       "3049                0.7669               0.9930                0.9494   \n",
       "3050                0.4852               0.9938                0.6917   \n",
       "3051                0.9128               1.0059                0.6218   \n",
       "3052                1.7681               0.9826                1.2788   \n",
       "3053                1.0170               0.9988                0.8297   \n",
       "3054                1.4044               0.9830                1.5111   \n",
       "3055                1.2807               0.9805                0.5912   \n",
       "3056                0.6606               0.9870                1.5597   \n",
       "3057                0.9063               0.9975                0.5852   \n",
       "3058                0.9859               0.9986                0.9472   \n",
       "3059                0.7514               1.0202                0.7579   \n",
       "3060                1.2142               0.9927                1.0987   \n",
       "3061                0.7631               0.9988                0.6831   \n",
       "3062                1.1912               1.0023                1.1929   \n",
       "3063                1.2957               1.0187                1.3258   \n",
       "3064                2.4987               1.0544                1.1116   \n",
       "3065                0.6363               1.0020                1.3808   \n",
       "3066                0.7470               0.9811                1.7409   \n",
       "3067                0.6748               0.9955                1.0464   \n",
       "3068                0.9467               0.9883                0.6067   \n",
       "3069                0.7223               0.9987                1.4928   \n",
       "3070                3.0621               1.0528                0.7324   \n",
       "3071                1.0118               1.0170                0.9045   \n",
       "3072                0.6873               0.9793                0.8752   \n",
       "3073                0.8941               1.0055                0.8393   \n",
       "3074                0.8377               0.9908                0.8447   \n",
       "3075                1.6346               0.9902                1.0559   \n",
       "3076                0.7533               1.0074                0.9841   \n",
       "3077                1.4603               1.0014                1.1665   \n",
       "3078                0.4918               0.9948                0.5889   \n",
       "3079                0.8940               0.9868                1.2333   \n",
       "3080                1.5452               1.0196                0.7416   \n",
       "3081                1.6422               1.0321                1.4789   \n",
       "3082                0.6491               0.9893                1.4020   \n",
       "3083                1.0302               1.0165                1.2732   \n",
       "3084                1.7811               1.0391                0.4719   \n",
       "3085                0.7847               0.9727                1.1242   \n",
       "3086                0.7031               0.9824                0.9468   \n",
       "3087                0.9749               1.0015                1.0249   \n",
       "3088                0.8691               0.9878                1.2615   \n",
       "3089                0.9696               1.0108                0.5807   \n",
       "3090                0.8801               0.9802                0.9945   \n",
       "3091                1.6079               0.9820                1.1462   \n",
       "3092                0.5891               1.0013                0.8125   \n",
       "3093                0.8950               0.9967                1.0859   \n",
       "3094                0.9267               0.9945                1.3586   \n",
       "\n",
       "      600310.SH_close_chg  600312.SH_amount_chg  600312.SH_close_chg  \\\n",
       "3045               1.0447                1.1879               0.9954   \n",
       "3046               0.9798                0.6822               0.9816   \n",
       "3047               0.9434                0.9900               1.0176   \n",
       "3048               0.9591                0.7819               0.9782   \n",
       "3049               1.0199                0.8844               1.0000   \n",
       "3050               0.9944                0.9895               0.9683   \n",
       "3051               0.9972                0.8333               1.0206   \n",
       "3052               0.9831                1.0537               0.9964   \n",
       "3053               0.9971                0.9929               0.9845   \n",
       "3054               1.0000                2.9515               1.0400   \n",
       "3055               0.9857                0.7070               0.9779   \n",
       "3056               0.9448                0.8278               0.9476   \n",
       "3057               0.9877                1.0401               1.0050   \n",
       "3058               1.0312                1.7062               1.0613   \n",
       "3059               0.9970                0.9312               0.9623   \n",
       "3060               1.0121                0.7479               1.0343   \n",
       "3061               0.9910                0.7173               0.9893   \n",
       "3062               0.9879                0.7122               1.0072   \n",
       "3063               1.0245                1.6381               1.0285   \n",
       "3064               1.0149                0.6248               0.9896   \n",
       "3065               1.0235                1.3908               1.0245   \n",
       "3066               1.0374                1.4174               1.0080   \n",
       "3067               1.0166                0.8195               1.0181   \n",
       "3068               0.9809                0.8813               0.9989   \n",
       "3069               1.0222                0.9816               0.9844   \n",
       "3070               0.9891                0.6880               0.9955   \n",
       "3071               1.0192                1.3997               1.0204   \n",
       "3072               0.9757                1.1450               0.9577   \n",
       "3073               0.9972                0.7809               0.9814   \n",
       "3074               0.9834                0.8383               0.9976   \n",
       "3075               1.0085                0.6730               1.0130   \n",
       "3076               0.9832                1.5089               0.9672   \n",
       "3077               0.9716                1.4021               0.9467   \n",
       "3078               0.9854                0.5007               0.9872   \n",
       "3079               1.0208                1.0342               0.9909   \n",
       "3080               1.0145                0.8328               1.0026   \n",
       "3081               1.0287                1.3013               1.0274   \n",
       "3082               1.0223                0.7617               1.0076   \n",
       "3083               1.0054                0.9168               0.9937   \n",
       "3084               0.9864                1.0548               0.9949   \n",
       "3085               0.9753                0.7289               0.9949   \n",
       "3086               0.9803                1.2397               0.9744   \n",
       "3087               0.9770                2.5633               0.9396   \n",
       "3088               0.9500                0.5638               0.9720   \n",
       "3089               0.9907                0.7959               0.9986   \n",
       "3090               1.0094                0.7213               1.0130   \n",
       "3091               1.0217                1.2484               1.0100   \n",
       "3092               0.9970                0.9879               1.0042   \n",
       "3093               0.9757                0.9353               0.9860   \n",
       "3094               0.9595                1.0629               0.9858   \n",
       "\n",
       "      600313.SH_amount_chg  600313.SH_close_chg  \n",
       "3045                0.6582               1.0016  \n",
       "3046                0.8872               1.0008  \n",
       "3047                1.2722               0.9754  \n",
       "3048                1.5606               0.9336  \n",
       "3049                0.5856               0.9739  \n",
       "3050                0.7427               0.9704  \n",
       "3051                0.8864               1.0153  \n",
       "3052                0.9581               1.0056  \n",
       "3053                1.0378               1.0019  \n",
       "3054                1.2109               0.9944  \n",
       "3055                1.0726               0.9850  \n",
       "3056                2.6347               1.0609  \n",
       "3057                0.6347               0.9552  \n",
       "3058                0.7923               0.9549  \n",
       "3059                0.6502               1.0088  \n",
       "3060                0.8029               1.0097  \n",
       "3061                1.4205               1.0125  \n",
       "3062                0.7774               0.9733  \n",
       "3063                0.8637               1.0088  \n",
       "3064                1.4126               1.0107  \n",
       "3065                1.9081               1.0375  \n",
       "3066                0.6964               1.0074  \n",
       "3067                2.3703               1.0708  \n",
       "3068                0.6013               0.9682  \n",
       "3069                1.2349               1.0204  \n",
       "3070                1.2392               1.0504  \n",
       "3071                1.0131               1.0372  \n",
       "3072                1.4850               1.0367  \n",
       "3073                0.9437               0.9569  \n",
       "3074                0.7519               1.0217  \n",
       "3075                0.7042               0.9811  \n",
       "3076                1.1465               0.9439  \n",
       "3077                0.6788               0.9626  \n",
       "3078                1.1301               1.0177  \n",
       "3079                0.6579               1.0000  \n",
       "3080                0.9580               0.9922  \n",
       "3081                1.3264               1.0210  \n",
       "3082                1.2618               1.0223  \n",
       "3083                0.8445               0.9548  \n",
       "3084                0.6752               0.9816  \n",
       "3085                0.8371               1.0063  \n",
       "3086                1.1480               0.9636  \n",
       "3087                0.7968               0.9760  \n",
       "3088                0.7850               0.9896  \n",
       "3089                0.6922               0.9971  \n",
       "3090                1.1743               1.0134  \n",
       "3091                2.1415               1.0312  \n",
       "3092                1.6762               1.0449  \n",
       "3093                0.6770               0.9684  \n",
       "3094                0.9340               0.9321  \n",
       "\n",
       "[50 rows x 2049 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd_train_data = pd.read_csv(os.path.join('data/stock', 'train.csv')).iloc[-1000:,:]\n",
    "# pd_train_data.iloc[:, range(1, pd_train_data.shape[1], 2)] = 1\n",
    "pd_val_data = pd.read_csv(os.path.join('data/stock', 'val.csv'))\n",
    "# pd_val_data.iloc[:, range(1, pd_val_data.shape[1], 2)] = 1\n",
    "\n",
    "n_embd = 256\n",
    "# 将NumPy数组转换为pandas DataFrame\n",
    "train_data = torch.tensor(pd_train_data.iloc[:, 1:n_embd+1].values, dtype=torch.float16)\n",
    "val_data = torch.tensor(pd_val_data.iloc[:100, 1:n_embd+1].values, dtype=torch.float16)\n",
    "\n",
    "pd_train_data.iloc[-50:,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ix=32, predict, probs=tensor([[0.1759, 0.0960, 0.0893, 0.0596, 0.0411, 0.0406, 0.0397, 0.0373, 0.0311,\n",
      "         0.0278]]), id=57, real=0.9638671875, topk=tensor([1.1006, 1.0469, 1.0410, 1.0322, 1.0273, 1.0215, 1.0205, 1.0205, 1.0137,\n",
      "        1.0137, 1.0117, 1.0107, 1.0088, 1.0078, 1.0068, 1.0059, 1.0059, 1.0049,\n",
      "        1.0039, 1.0020, 1.0020, 1.0000, 1.0000, 1.0000, 0.9985, 0.9971, 0.9971,\n",
      "        0.9951, 0.9946, 0.9946], dtype=torch.float16)\n",
      "ix=33, predict, probs=tensor([[0.1802, 0.1277, 0.0977, 0.0676, 0.0472, 0.0448, 0.0431, 0.0420, 0.0340,\n",
      "         0.0297]]), id=117, real=0.9853515625, topk=tensor([1.0996, 1.0996, 1.0996, 1.0928, 1.0742, 1.0674, 1.0596, 1.0537, 1.0449,\n",
      "        1.0352, 1.0283, 1.0283, 1.0264, 1.0234, 1.0225, 1.0205, 1.0195, 1.0176,\n",
      "        1.0176, 1.0166, 1.0166, 1.0156, 1.0156, 1.0146, 1.0137, 1.0127, 1.0127,\n",
      "        1.0127, 1.0117, 1.0117], dtype=torch.float16)\n",
      "ix=34, predict, probs=tensor([[0.3030, 0.1009, 0.0782, 0.0617, 0.0460, 0.0370, 0.0300, 0.0270, 0.0230,\n",
      "         0.0208]]), id=78, real=1.046875, topk=tensor([1.1016, 1.0996, 1.0713, 1.0518, 1.0498, 1.0469, 1.0459, 1.0410, 1.0410,\n",
      "        1.0371, 1.0371, 1.0371, 1.0361, 1.0352, 1.0332, 1.0332, 1.0312, 1.0303,\n",
      "        1.0293, 1.0283, 1.0264, 1.0254, 1.0254, 1.0254, 1.0244, 1.0244, 1.0244,\n",
      "        1.0234, 1.0225, 1.0225], dtype=torch.float16)\n",
      "ix=35, predict, probs=tensor([[0.6772, 0.0599, 0.0224, 0.0214, 0.0201, 0.0190, 0.0146, 0.0143, 0.0103,\n",
      "         0.0099]]), id=29, real=0.97265625, topk=tensor([1.1006, 1.1006, 1.1006, 1.1006, 1.0469, 1.0430, 1.0400, 1.0391, 1.0361,\n",
      "        1.0342, 1.0342, 1.0332, 1.0312, 1.0312, 1.0312, 1.0283, 1.0254, 1.0254,\n",
      "        1.0254, 1.0244, 1.0234, 1.0234, 1.0234, 1.0225, 1.0225, 1.0225, 1.0215,\n",
      "        1.0195, 1.0195, 1.0176], dtype=torch.float16)\n",
      "ix=36, predict, probs=tensor([[0.1590, 0.1566, 0.0796, 0.0728, 0.0565, 0.0501, 0.0326, 0.0318, 0.0222,\n",
      "         0.0207]]), id=14, real=1.0126953125, topk=tensor([1.1006, 1.0996, 1.0791, 1.0771, 1.0771, 1.0586, 1.0527, 1.0498, 1.0430,\n",
      "        1.0420, 1.0400, 1.0400, 1.0391, 1.0391, 1.0381, 1.0371, 1.0361, 1.0361,\n",
      "        1.0361, 1.0342, 1.0332, 1.0322, 1.0312, 1.0303, 1.0283, 1.0264, 1.0264,\n",
      "        1.0244, 1.0244, 1.0234], dtype=torch.float16)\n",
      "ix=37, predict, probs=tensor([[0.2038, 0.0885, 0.0633, 0.0537, 0.0499, 0.0436, 0.0375, 0.0339, 0.0313,\n",
      "         0.0297]]), id=38, real=1.013671875, topk=tensor([1.0732, 1.0684, 1.0674, 1.0498, 1.0498, 1.0469, 1.0410, 1.0400, 1.0371,\n",
      "        1.0342, 1.0293, 1.0225, 1.0215, 1.0215, 1.0205, 1.0166, 1.0166, 1.0156,\n",
      "        1.0137, 1.0137, 1.0137, 1.0127, 1.0117, 1.0117, 1.0107, 1.0107, 1.0107,\n",
      "        1.0098, 1.0088, 1.0068], dtype=torch.float16)\n",
      "ix=38, predict, probs=tensor([[0.0905, 0.0765, 0.0567, 0.0536, 0.0473, 0.0431, 0.0391, 0.0366, 0.0337,\n",
      "         0.0274]]), id=87, real=1.0166015625, topk=tensor([1.1006, 1.0996, 1.0498, 1.0439, 1.0381, 1.0342, 1.0283, 1.0244, 1.0215,\n",
      "        1.0195, 1.0166, 1.0166, 1.0156, 1.0146, 1.0137, 1.0137, 1.0127, 1.0127,\n",
      "        1.0127, 1.0117, 1.0088, 1.0088, 1.0078, 1.0068, 1.0068, 1.0059, 1.0059,\n",
      "        1.0059, 1.0039, 1.0039], dtype=torch.float16)\n",
      "ix=39, predict, probs=tensor([[0.1719, 0.1482, 0.0768, 0.0715, 0.0572, 0.0517, 0.0320, 0.0278, 0.0244,\n",
      "         0.0210]]), id=66, real=0.99267578125, topk=tensor([1.0996, 1.0996, 1.0996, 1.0469, 1.0430, 1.0381, 1.0361, 1.0352, 1.0342,\n",
      "        1.0332, 1.0322, 1.0293, 1.0283, 1.0273, 1.0264, 1.0254, 1.0244, 1.0225,\n",
      "        1.0225, 1.0205, 1.0205, 1.0195, 1.0195, 1.0186, 1.0166, 1.0156, 1.0156,\n",
      "        1.0156, 1.0156, 1.0156], dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 256])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = 32\n",
    "\n",
    "data = train_data[-50:]\n",
    "\n",
    "for ix in range(32, 50):\n",
    "    x = data[ix-block:ix, :]\n",
    "    value, indices = model.generate_last(x.unsqueeze(0), top_k=10)\n",
    "    if value[0][0] > 0.0:\n",
    "        print(f'ix={ix}, predict, probs={value}, id={indices[0,0]}, real={data[ix, indices[0,0]*2+1]}, topk={(data[ix, range(1,data.shape[1],2)]).topk(30)[0]}')\n",
    "    \n",
    "\n",
    "\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3010299956639812"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log10(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[335], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     \u001b[39mwith\u001b[39;00m ctx:  \n\u001b[0;32m----> 4\u001b[0m         probs, index \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate_last(eval_X, top_k\u001b[39m=\u001b[39mtop_k)\n\u001b[1;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict index is \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m}\u001b[39;00m\u001b[39m, index.shape is \u001b[39m\u001b[39m{\u001b[39;00mindex\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict probs is \u001b[39m\u001b[39m{\u001b[39;00mprobs\u001b[39m}\u001b[39;00m\u001b[39m, probs.shape is \u001b[39m\u001b[39m{\u001b[39;00mprobs\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_X' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# run generation\n",
    "with torch.no_grad():\n",
    "    with ctx:  \n",
    "        probs, index = model.generate_last(eval_X, top_k=top_k)\n",
    "        print(f'predict index is {index}, index.shape is {index.shape}')\n",
    "        print(f'predict probs is {probs}, probs.shape is {probs.shape}')\n",
    "        print('---------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
