{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4210,"status":"ok","timestamp":1712472084054,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"ECcL8suYCTCU"},"outputs":[],"source":["\n","\"\"\"\n","This training script can be run both on a single gpu in debug mode,\n","and also in a larger training run with distributed data parallel (ddp).\n","\n","To run on a single GPU, example:\n","$ python train.py --batch_size=32 --compile=False\n","\n","To run with DDP on 4 gpus on 1 node, example:\n","$ torchrun --standalone --nproc_per_node=4 train.py\n","\n","To run with DDP on 4 gpus across 2 nodes, example:\n","- Run on the first (master) node with example IP 123.456.123.456:\n","$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py\n","- Run on the worker node:\n","$ torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py\n","(If your cluster does not have Infiniband interconnect prepend NCCL_IB_DISABLE=1)\n","\"\"\"\n","\n","import os\n","import time\n","import math\n","import pickle\n","import json\n","from contextlib import nullcontext\n","\n","import pandas as pd\n","\n","import numpy as np\n","import torch\n","from torch.nn.parallel import DistributedDataParallel as DDP\n","from torch.distributed import init_process_group, destroy_process_group\n","\n","\n","from model import GPTConfig, GPT\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":717,"status":"ok","timestamp":1712475540054,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"FGVqvzN6ALYo","outputId":"fa309dba-2f7f-4306-dba4-e8416d354f7c"},"outputs":[],"source":["\n","\n","# -----------------------------------------------------------------------------\n","# default config values designed to train a gpt2 (124M) on OpenWebText\n","# I/O\n","out_dir = 'out-stock'\n","eval_interval = 100\n","log_interval = 100\n","eval_iters = 20\n","eval_only = False # if True, script exits right after the first eval\n","always_save_checkpoint = False # if True, always save a checkpoint after each eval\n","init_from = 'scratch' # 'scratch' or 'resume' or 'gpt2*'\n","# wandb logging\n","wandb_log = False # disabled by default\n","wandb_project = 'stock'\n","wandb_run_name = 'mini-gpt' # 'run' + str(time.time())\n","# data\n","dataset = 'stock'\n","gradient_accumulation_steps = 1 # used to simulate larger batch sizes\n","batch_size = 24 # if gradient_accumulation_steps > 1, this is the micro-batch size\n","block_size = 20\n","# model\n","n_layer = 4\n","n_head = 4\n","n_embd = 64 # 参数估计：params= layer*(12*emb**2), 数据量估计dataSize= 10 *params\n","# dropout = 0.998728434 # for pretraining 0 is good, for finetuning try 0.1+\n","dropout = 0\n","# dropout = 1-dataSize/10/params\n","bias = False # do we use bias inside LayerNorm and Linear layers?\n","meta_vocab_size = n_embd // 2\n","\n","# adamw optimizer\n","learning_rate = 1e-3 # max learning rate\n","max_iters = 8e5 # total number of training iterations\n","weight_decay = 1e-1\n","beta1 = 0.9\n","beta2 = 0.99\n","grad_clip = 1.0 # clip gradients at this value, or disable if == 0.0\n","# learning rate decay settings\n","decay_lr = True # whether to decay the learning rate\n","warmup_iters = 100 # how many steps to warm up for\n","lr_decay_iters = 2000 # should be ~= max_iters per Chinchilla\n","min_lr = 1e-3 # minimum learning rate, should be ~= learning_rate/10 per Chinchilla\n","\n","# system\n","device = 'cuda' if torch.cuda.is_available() else 'cpu' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks\n","dtype = 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n","# -----------------------------------------------------------------------------\n","config_keys = [k for k,v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))]\n","config = {k: globals()[k] for k in config_keys} # will be useful for logging\n","# -----------------------------------------------------------------------------\n","\n","master_process = True\n","\n","\n","if master_process:\n","    os.makedirs(out_dir, exist_ok=True)\n","torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n","torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n","device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n","# note: float16 data type will automatically use a GradScaler\n","ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n","ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n","\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":798,"status":"ok","timestamp":1712475545909,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"KAiEazf6ALYq","outputId":"1d946771-617f-42af-c008-bed1ffbfabef"},"outputs":[],"source":["\n","datadir = os.path.join('data', dataset)\n","\n","# meta数据\n","meta = {}\n","with open(os.path.join(datadir, 'meta.pkl'), 'r') as f:\n","    meta = json.load(f)\n","    meta_vocab_size = meta['vocab_size']\n","    meta_vocab_size = 5\n","def decode(id):\n","    return meta['itos'][str(id)]\n","def encode(s):\n","    return [meta['stoi'][c] for c in s]\n","\n","\n","df_data = pd.read_csv(os.path.join(datadir, 'train.csv')).iloc[1:,:5001]\n","\n","length = len(df_data)\n","pd_train_data = df_data.iloc[:int(length*0.95)]\n","pd_train_data.reset_index(drop=True, inplace=True)\n","\n","pd_val_data = df_data.iloc[int(length*0.95)-block_size:int(length*0.98)]\n","pd_val_data = df_data.iloc[int(length*0.95)-block_size:int(length*0.98)]\n","pd_val_data.reset_index(drop=True, inplace=True)\n","\n","pd_test_data = df_data.iloc[int(length*0.98)-block_size:]\n","pd_test_data.reset_index(drop=True, inplace=True)\n","\n","\n","pd_train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":824,"status":"ok","timestamp":1712475549685,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"1UDMxF_GALYq","outputId":"99d39459-ac06-406c-8479-6715c6a942b6"},"outputs":[],"source":["pd_val_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":858,"status":"ok","timestamp":1712475554193,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"Q31sUBPXALYq","outputId":"3827d27e-28bf-4d54-b8b5-84d6ec32c93f"},"outputs":[],"source":["pd_test_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1000,"status":"ok","timestamp":1712475558458,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"Lb3FD23NIqgH","outputId":"4beb6040-36c4-4da9-dc18-d7ac87d5cf14"},"outputs":[],"source":["def transform_dataframe_id(df):\n","  \"\"\"\n","  Transforms values in a dataframe according to the specified rules.\n","\n","  Args:\n","      df: The pandas dataframe to transform.\n","\n","  Returns:\n","      A new pandas dataframe with transformed values.\n","  \"\"\"\n","\n","  def transform_pri_chg_id(value):\n","    if value == -100 or value is None:\n","      value = 1\n","\n","    new_value = (value - 1)*100\n","    if new_value < -6:\n","      return 0\n","    elif new_value < -2:\n","      return 1\n","    elif new_value < 2:\n","      return 2\n","    elif new_value < 6:\n","      return 3\n","    else:\n","      return 4\n","\n","  # Apply the transformation function to each column in the dataframe\n","  transformed_df = df.applymap(transform_pri_chg_id)\n","\n","  return transformed_df\n","\n","transform_dataframe_id(pd_test_data.iloc[:, 1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5471,"status":"ok","timestamp":1712472669785,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"WPldMiSLALYr","outputId":"805df911-7054-45d8-e552-99cd910fceb4"},"outputs":[],"source":["train_data = transform_dataframe_id(pd_train_data.iloc[:, 1:])\n","val_data = transform_dataframe_id(pd_val_data.iloc[:, 1:])\n","test_data = transform_dataframe_id(pd_test_data.iloc[:, 1:])\n","\n","\n","train_data = torch.from_numpy(train_data.to_numpy().astype(np.int64))\n","val_data = torch.from_numpy(val_data.to_numpy().astype(np.int64))\n","test_data = torch.from_numpy(test_data.to_numpy().astype(np.int64))\n","\n","print(f'train.shape is {train_data.shape}, val.shape is {val_data.shape}')\n","train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":723,"status":"ok","timestamp":1712472677348,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"PJXXvFqSALYr","outputId":"86a89a7f-8fd7-4dc5-a558-34ef6b7668db"},"outputs":[],"source":["# 写个python程序，从pandas数据中获取一批训练数据：\n","# 1. 读取pandas数据A，格式是：[trade_date, label1, label2, label3，。。。]，date的样例有：20230104，label*是数字，样例有1.0399、0.9943\n","# 2. X是生成指定格式的shape = [shape, ]\n","\n","import random\n","\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    pd_data = pd_train_data if split == 'train' else pd_val_data\n","    # data = val_data\n","\n","    index_codes = torch.randint(data.shape[1], (batch_size, ))\n","    indices_block = torch.randint(data.shape[0]-1-block_size, (batch_size, ))\n","\n","    # (batch, block)\n","    x = torch.stack([data[i:i+block_size, j].squeeze() for i,j in zip(indices_block, index_codes)])\n","    # (batch, block)\n","    y = torch.stack([data[i+1:i+1+block_size, j].squeeze() for i,j in zip(indices_block, index_codes)])\n","\n","    # index_first = indices_block[0].item()\n","    # index_code = index_codes[0].item()\n","    # for i in range(block_size):\n","    #     print(f'x is date={pd_data.iloc[index_first+i, 0]}, chg={pd_data.iloc[index_first+i, index_code+1]:<6}, code={pd_data.columns[index_code+1]}, code_id={index_code+1}')\n","    # print('----')\n","    # for i in range(block_size):\n","    #      print(f'y is date={pd_data.iloc[index_first+i+1, 0]}, chg={pd_data.iloc[index_first+i+1, index_code+1]:<6}, code={pd_data.columns[index_code+1]}, code_id={index_code+1}')\n","\n","    return x, y\n","\n","print(train_data.shape)\n","x, y = get_batch('train')\n","\n","print(f'x.shape is {x.shape}, y.shape is {y.shape}')\n","x\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":819,"status":"ok","timestamp":1712472685330,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"id0RPMKYALYr","outputId":"a9a11934-7d5a-421e-989a-1d247109a75e"},"outputs":[],"source":["# init these up here, can override if init_from='resume' (i.e. from a checkpoint)\n","iter_num = 0\n","best_val_loss = 1e9\n","\n","# model init\n","model_args = dict(n_layer=n_layer, n_head=n_head, n_embd=n_embd, block_size=block_size,\n","                  bias=bias, vocab_size=meta_vocab_size, dropout=dropout) # start with model_args from command line\n","if init_from == 'scratch':\n","    # init a new model from scratch\n","    print(\"Initializing a new model from scratch\")\n","    gptconf = GPTConfig(**model_args)\n","    model = GPT(gptconf)\n","elif init_from == 'resume':\n","    print(f\"Resuming training from {out_dir}\")\n","    # resume training from a checkpoint.\n","    ckpt_path = os.path.join(out_dir, 'ckpt.pt')\n","    checkpoint = torch.load(ckpt_path, map_location=device)\n","    checkpoint_model_args = checkpoint['model_args']\n","    # force these config attributes to be equal otherwise we can't even resume training\n","    # the rest of the attributes (e.g. dropout) can stay as desired from command line\n","    for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n","        model_args[k] = checkpoint_model_args[k]\n","    # create the model\n","    gptconf = GPTConfig(**model_args)\n","    model = GPT(gptconf)\n","    state_dict = checkpoint['model']\n","    # fix the keys of the state dictionary :(\n","    # honestly no idea how checkpoints sometimes get this prefix, have to debug more\n","    unwanted_prefix = '_orig_mod.'\n","    for k,v in list(state_dict.items()):\n","        if k.startswith(unwanted_prefix):\n","            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n","    model.load_state_dict(state_dict)\n","    iter_num = checkpoint['iter_num']\n","    best_val_loss = checkpoint['best_val_loss']\n","\n","\n","model.to(device)\n","\n","# initialize a GradScaler. If enabled=False scaler is a no-op\n","scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n","\n","# optimizer\n","optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n","\n","checkpoint = None # free up memory\n","\n","# helps estimate an arbitrarily accurate loss over either split using many batches\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            with ctx:\n","                logits, loss = model(X.to(device), Y.to(device))\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","# logging\n","if wandb_log and master_process:\n","    import wandb\n","    wandb.init(project=wandb_project, name=wandb_run_name, config=config)\n","\n","X, Y = get_batch('train')\n","\n","\n","print(f'X is {X}')\n","print(f'Y is {Y}')\n","logits, loss = model(X.to(device), Y.to(device))\n","print(logits.shape)\n","# print(f'logits is {logits}, shape is {logits.shape}')\n","# print(f'loss is {loss}, loss.shape is {loss.shape}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":824647,"status":"ok","timestamp":1712473520421,"user":{"displayName":"Yabin Ren","userId":"08604408658120971320"},"user_tz":-480},"id":"XoO4cdznALYs","outputId":"e32a4667-929f-44e0-892e-0e2945e908b3"},"outputs":[],"source":["\n","\n","# training loop\n","# X, Y = get_batch('train') # fetch the very first batch\n","t0 = time.time()\n","local_iter_num = 0 # number of iterations in the lifetime of this process\n","raw_model = model # unwrap DDP container if needed\n","running_mfu = -1.0\n","\n","dates, codes = train_data.shape\n","\n","while True:\n","    # evaluate the loss on train/val sets and write checkpoints\n","    if iter_num % eval_interval == 0 and master_process:\n","        losses = estimate_loss()\n","        print(f\"step {iter_num}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","        if losses['val'] < best_val_loss or always_save_checkpoint:\n","            best_val_loss = losses['val']\n","            if iter_num >= 0:\n","                checkpoint = {\n","                    'model': raw_model.state_dict(),\n","                    'optimizer': optimizer.state_dict(),\n","                    'model_args': model_args,\n","                    'iter_num': iter_num,\n","                    'best_val_loss': best_val_loss,\n","                    'config': config,\n","                }\n","                print(f\"saving checkpoint to {out_dir}\")\n","                torch.save(checkpoint, os.path.join(out_dir, 'ckpt.pt'))\n","\n","    if iter_num == 0 and eval_only:\n","        break\n","\n","    X, Y = get_batch('train')\n","    logits, loss = model(X.to(device), Y.to(device))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    # timing and logging\n","    t1 = time.time()\n","    dt = t1 - t0\n","    t0 = t1\n","    if iter_num % log_interval == 0 and master_process:\n","        # get loss as float. note: this is a CPU-GPU sync point\n","        # scale up to undo the division above, approximating the true total loss (exact would have been a sum)\n","        lossf = loss.item() * gradient_accumulation_steps\n","        print(f\"iter {iter_num}: loss {lossf:.4f}, time {dt*1000:.2f}ms, epoch {int(iter_num*batch_size/dates/codes)}\")\n","    iter_num += 1\n","    local_iter_num += 1\n","\n","    # termination conditions\n","    if iter_num > max_iters:\n","        break\n","\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ren545457803/nanoGPT/blob/stock/train.ipynb","timestamp":1712232385446}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
